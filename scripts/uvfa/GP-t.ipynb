{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Decaying Gaussian Process UCB Algorithms\n",
    "## Minimal Verifying Problem\n",
    "\n",
    "See ideas at https://www.dropbox.com/s/krqreih872ionmo/%5BIdea%5D%20GP-t%20Algorithm.pdf?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import scriptinit\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import numpy.linalg as npla\n",
    "from matplotlib.pyplot import *\n",
    "from pyrl.algorithms.uvfa import *\n",
    "from pyrl.algorithms.valueiter import *\n",
    "from pyrl.tasks.gridworld import *\n",
    "from pyrl.algorithms.nn import *\n",
    "from pyrl.agents.agent import *\n",
    "from pyrl.agents.multitask import *\n",
    "from pyrl.algorithms.multitask import *\n",
    "import pyrl.agents.arch as arch\n",
    "from pyrl.prob import *\n",
    "from pyrl.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showV(v):\n",
    "    imshow(v.reshape(H, W), interpolation='none')\n",
    "    print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXSwuODFSSJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb42a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# world 2\n",
    "H = W = 6\n",
    "grid = np.zeros((H, W))\n",
    "grid[2:4, 2:4] = 1.\n",
    "showV(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tasks = generate_gridworlds(grid)\n",
    "random.shuffle(all_tasks)\n",
    "tasks = all_tasks[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network architecture.\n",
    "# shared weights between state and goal due to symmetry.\n",
    "def two_stream_arch(states, input_dim=H * W, output_dim=4):\n",
    "    params = []\n",
    "    ## agent.\n",
    "    H_AGENT_DIM1 = 8\n",
    "    fc_agent1 = layers.FullyConnected(input_dim, H_AGENT_DIM1, activation='relu')\n",
    "    h_agent1 = fc_agent1(states[:, :input_dim])\n",
    "    h_goal1 = fc_agent1(states[:, input_dim:2*input_dim]) # shared weights.\n",
    "    ## combine them all!\n",
    "    v_joint = T.concatenate([h_agent1, h_goal1], axis=1)\n",
    "    H_JOINT_DIM = 32\n",
    "    fc_joint = layers.FullyConnected(2 * H_AGENT_DIM1, H_JOINT_DIM, activation='relu')\n",
    "    linear_layer = layers.FullyConnected(H_JOINT_DIM, output_dim, activation=None)\n",
    "    \n",
    "    output = linear_layer(fc_joint(v_joint))\n",
    "    \n",
    "    model = {\n",
    "        'fc_agent1': fc_agent1,\n",
    "        'fc_joint': fc_joint,\n",
    "        'linear_layer': linear_layer\n",
    "    }\n",
    "    return (output, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(task1, task2):\n",
    "    pos1 = task1.goal.keys()[0]\n",
    "    pos2 = task2.goal.keys()[0]\n",
    "    return np.abs(pos1[0] - pos2[0])+ np.abs(pos1[1] - pos2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dqn = DQN(tasks[0], lambda states: arch.two_layer(states, H * W * 2, 32, 4))\n",
    "dqn = DQN(tasks[0], two_stream_arch)\n",
    "learner = SingleLearnerGPt(dqn, tasks, dist=dist, \n",
    "                           gpt_eta=1e-2, gpt_r=1. / (H + W), gpt_v=1e-2, gpt_sigma=1e-1, gpt_kappa=1e-2,\n",
    "                           lr=1e-4, memory_size=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[chosen task]  1\n",
      "mu None\n",
      "sigma None\n",
      "ucb None\n",
      "performance 0.0938175353254 progress 0.0270039060612\n",
      "task rewards [ 0.08492933  0.13607545  0.09866171  0.05560365]\n",
      "[chosen task]  1\n",
      "mu [ 0.00166446  0.01336761  0.01229879  0.00166446]\n",
      "sigma [ 0.01992402  0.01509901  0.0158514   0.01992402]\n",
      "ucb [ 0.0018637   0.0135186   0.01245731  0.0018637 ]\n",
      "performance 0.103514835314 progress 0.00969729998901\n",
      "task rewards [ 0.08667918  0.16978796  0.10752151  0.05007069]\n",
      "[chosen task]  1\n",
      "mu [ 0.00145956  0.01172203  0.01078479  0.00145956]\n",
      "sigma [ 0.01990127  0.0136317   0.01460935  0.01990127]\n",
      "ucb [ 0.00165858  0.01185835  0.01093088  0.00165858]\n",
      "performance 0.0880043893665 progress -0.0155104459479\n",
      "task rewards [ 0.08342787  0.1300665   0.100106    0.03841719]\n",
      "[chosen task]  1\n",
      "mu [ 0.00044287  0.00355674  0.00327236  0.00044287]\n",
      "sigma [ 0.01989248  0.01306496  0.01412962  0.01989248]\n",
      "ucb [ 0.00064179  0.00368739  0.00341365  0.00064179]\n",
      "performance 0.109449672917 progress 0.0214452835503\n",
      "task rewards [ 0.0834138   0.15199637  0.11375493  0.08863359]\n",
      "[chosen task]  1\n",
      "mu [ 0.0008893   0.00714213  0.00657108  0.0008893 ]\n",
      "sigma [ 0.01988928  0.01285856  0.0139549   0.01988928]\n",
      "ucb [ 0.00108819  0.00727072  0.00671063  0.00108819]\n",
      "performance 0.150254658159 progress 0.0408049852418\n",
      "task rewards [ 0.19052567  0.25978737  0.11860247  0.03210312]\n",
      "[chosen task]  1\n",
      "mu [ 0.00182412  0.01464982  0.01347849  0.00182412]\n",
      "sigma [ 0.01988843  0.01280367  0.01390844  0.01988843]\n",
      "ucb [ 0.002023    0.01477786  0.01361757  0.002023  ]\n",
      "performance 0.162495586207 progress 0.0122409280487\n",
      "task rewards [ 0.19200306  0.32608179  0.11473651  0.01716099]\n",
      "[chosen task]  1\n",
      "mu [ 0.00172097  0.01382148  0.01271637  0.00172097]\n",
      "sigma [ 0.01988835  0.01279856  0.01390411  0.01988835]\n",
      "ucb [ 0.00191986  0.01394946  0.01285541  0.00191986]\n",
      "performance 0.173457467076 progress 0.0109618808689\n",
      "task rewards [ 0.19179647  0.37037389  0.11513549  0.01652402]\n",
      "[chosen task]  1\n",
      "mu [ 0.00156701  0.012585    0.01157876  0.00156701]\n",
      "sigma [ 0.01988832  0.0127969   0.01390271  0.01988832]\n",
      "ucb [ 0.0017659   0.01271297  0.01171779  0.0017659 ]\n",
      "performance 0.17711765833 progress 0.00366019125428\n",
      "task rewards [ 0.19384837  0.37681601  0.13143716  0.00636909]\n",
      "[chosen task]  1\n",
      "mu [ 0.00119767  0.00961871  0.00884964  0.00119767]\n",
      "sigma [ 0.01988814  0.01278525  0.01389285  0.01988814]\n",
      "ucb [ 0.00139655  0.00974656  0.00898857  0.00139655]\n",
      "performance 0.18470273615 progress 0.00758507781926\n",
      "task rewards [ 0.19921761  0.45654912  0.06700914  0.01603507]\n",
      "[chosen task]  1\n",
      "mu [ 0.00099866  0.00802046  0.00737918  0.00099866]\n",
      "sigma [ 0.01988785  0.01276632  0.01387683  0.01988785]\n",
      "ucb [ 0.00119754  0.00814812  0.00751795  0.00119754]\n",
      "performance 0.194208822541 progress 0.0095060863914\n",
      "task rewards [ 0.1915181   0.48829792  0.08109917  0.01592011]\n",
      "[chosen task]  1\n",
      "mu [ 0.00089573  0.00719375  0.00661857  0.00089573]\n",
      "sigma [ 0.01988755  0.0127471   0.01386055  0.01988755]\n",
      "ucb [ 0.0010946   0.00732122  0.00675718  0.0010946 ]\n",
      "performance 0.198557008558 progress 0.00434818601687\n",
      "task rewards [ 0.18585555  0.45276285  0.13986551  0.01574413]\n",
      "[chosen task]  1\n",
      "mu [ 0.00067012  0.00538186  0.00495155  0.00067012]\n",
      "sigma [ 0.01988733  0.01273262  0.01384829  0.01988733]\n",
      "ucb [ 0.00086899  0.00550918  0.00509003  0.00086899]\n",
      "performance 0.234601272476 progress 0.0360442639186\n",
      "task rewards [ 0.07958802  0.69356205  0.1493416   0.01591343]\n",
      "[chosen task]  1\n",
      "mu [ 0.00143533  0.0115274   0.01060572  0.00143533]\n",
      "sigma [ 0.0198872   0.01272433  0.01384128  0.0198872 ]\n",
      "ucb [ 0.0016342   0.01165465  0.01074414  0.0016342 ]\n",
      "performance 0.216562577368 progress -0.0180386951083\n",
      "task rewards [ 0.18600754  0.5766388   0.08814764  0.01545633]\n",
      "[chosen task]  1\n",
      "mu [ 0.00049847  0.00400328  0.0036832   0.00049847]\n",
      "sigma [ 0.01988715  0.01272097  0.01383844  0.01988715]\n",
      "ucb [ 0.00069734  0.00413049  0.00382158  0.00069734]\n",
      "performance 0.258049070652 progress 0.041486493284\n",
      "task rewards [ 0.16759972  0.65769658  0.19360185  0.01329814]\n",
      "[chosen task]  1\n",
      "mu [ 0.00146643  0.0117772   0.01083555  0.00146643]\n",
      "sigma [ 0.01988714  0.01272027  0.01383784  0.01988714]\n",
      "ucb [ 0.0016653   0.0119044   0.01097393  0.0016653 ]\n",
      "performance 0.239450730436 progress -0.0185983402158\n",
      "task rewards [ 0.18600754  0.59531218  0.16098416  0.01549905]\n",
      "[chosen task]  1\n",
      "mu [ 0.00052705  0.00423285  0.00389441  0.00052705]\n",
      "sigma [ 0.01988714  0.01272027  0.01383784  0.01988714]\n",
      "ucb [ 0.00072592  0.00436005  0.00403279  0.00072592]\n",
      "performance 0.27759619381 progress 0.0381454633738\n",
      "task rewards [ 0.18591485  0.76750456  0.14148652  0.01547884]\n",
      "[chosen task]  1\n",
      "mu [ 0.00140416  0.01127705  0.01037539  0.00140416]\n",
      "sigma [ 0.01988713  0.01271995  0.01383757  0.01988713]\n",
      "ucb [ 0.00160303  0.01140425  0.01051376  0.00160303]\n",
      "performance 0.183215032884 progress -0.0943811609258\n",
      "task rewards [ 0.07959893  0.51754768  0.11455076  0.02116277]\n",
      "[chosen task]  0\n",
      "mu [-0.001749   -0.01404654 -0.01292344 -0.001749  ]\n",
      "sigma [ 0.01988712  0.01271912  0.01383687  0.01988712]\n",
      "ucb [-0.00155013 -0.01391935 -0.01278507 -0.00155013]\n",
      "performance 0.260826967984 progress 0.0776119350994\n",
      "task rewards [ 0.1574286   0.62129626  0.08416272  0.1804203 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.03706253 -0.01472571 -0.00766001 -0.00225535]\n",
      "sigma [ 0.01507515  0.0134219   0.01427116  0.01989795]\n",
      "ucb [ 0.03721328 -0.01459149 -0.0075173  -0.00205638]\n",
      "performance 0.274101886248 progress 0.0132749182641\n",
      "task rewards [ 0.30166187  0.63583568  0.09172749  0.06718251]\n",
      "[chosen task]  0\n",
      "mu [ 0.0276523  -0.01657929 -0.01075502 -0.00238661]\n",
      "sigma [ 0.01362347  0.01422521  0.01489073  0.0199105 ]\n",
      "ucb [ 0.02778854 -0.01643704 -0.01060611 -0.00218751]\n",
      "performance 0.395472420163 progress 0.121370533915\n",
      "task rewards [ 0.6551838   0.66261055  0.08864727  0.17544806]\n",
      "[chosen task]  0\n",
      "mu [ 0.05174466 -0.01550281 -0.00613767 -0.00251238]\n",
      "sigma [ 0.01306145  0.01508365  0.01558274  0.01992396]\n",
      "ucb [ 0.05187527 -0.01535198 -0.00598184 -0.00231314]\n",
      "performance 0.34623020796 progress -0.0492422122032\n",
      "task rewards [ 0.65999255  0.64306424  0.02115202  0.06071202]\n",
      "[chosen task]  0\n",
      "mu [ 0.02458614 -0.01788351 -0.01239455 -0.00251752]\n",
      "sigma [ 0.01285666  0.01594676  0.01628842  0.01993751]\n",
      "ucb [ 0.02471471 -0.01772404 -0.01223166 -0.00231814]\n",
      "performance 0.314494854568 progress -0.031735353392\n",
      "task rewards [ 0.62953725  0.53589366  0.0178769   0.0746716 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00720416 -0.01906447 -0.01609019 -0.00247767]\n",
      "sigma [ 0.01280235  0.01676622  0.01696078  0.0199504 ]\n",
      "ucb [ 0.00733218 -0.0188968  -0.01592059 -0.00227816]\n",
      "performance 0.353937842299 progress 0.0394429877308\n",
      "task rewards [ 0.64506938  0.60611101  0.08380273  0.08076825]\n",
      "[chosen task]  0\n",
      "mu [ 0.01050823 -0.01741238 -0.01410116 -0.00230556]\n",
      "sigma [ 0.01279751  0.01750303  0.01756432  0.01996202]\n",
      "ucb [ 0.01063621 -0.01723735 -0.01392551 -0.00210594]\n",
      "performance 0.349497510917 progress -0.00444033138185\n",
      "task rewards [ 0.72911182  0.57048109  0.01762888  0.08076825]\n",
      "[chosen task]  0\n",
      "mu [ 0.0034804  -0.0166368  -0.01446612 -0.00213173]\n",
      "sigma [ 0.01279608  0.01813194  0.01807732  0.01997196]\n",
      "ucb [ 0.00360836 -0.01645548 -0.01428534 -0.00193201]\n",
      "performance 0.362181155279 progress 0.0126836443621\n",
      "task rewards [ 0.76123991  0.59963568  0.01489191  0.07295713]\n",
      "[chosen task]  0\n",
      "mu [ 0.00251789 -0.01484085 -0.01299333 -0.00189524]\n",
      "sigma [ 0.01278466  0.01864258  0.01849174  0.01998005]\n",
      "ucb [ 0.00264574 -0.01465443 -0.01280841 -0.00169544]\n",
      "performance 0.341358435802 progress -0.0208227194771\n",
      "task rewards [ 0.72590664  0.52756763  0.01464771  0.09731177]\n",
      "[chosen task]  3\n",
      "mu [-0.00548734 -0.01383954 -0.01330282 -0.0016824 ]\n",
      "sigma [ 0.01276593  0.0190376   0.01881082  0.01998632]\n",
      "ucb [-0.00535968 -0.01364916 -0.01311471 -0.00148254]\n",
      "performance 0.177749001073 progress -0.163609434728\n",
      "task rewards [ 0.27693037  0.3447513   0.02960813  0.0597062 ]\n",
      "[chosen task]  0\n",
      "mu [-0.00777917 -0.02132926 -0.01533358 -0.08156012]\n",
      "sigma [ 0.0134773   0.01927586  0.01908923  0.01509762]\n",
      "ucb [-0.0076444  -0.0211365  -0.01514269 -0.08140915]\n",
      "performance 0.199642067046 progress 0.0218930659722\n",
      "task rewards [ 0.43493354  0.24931072  0.0564464   0.05787761]\n",
      "[chosen task]  0\n",
      "mu [-0.00079888 -0.01835443 -0.01174456 -0.07894537]\n",
      "sigma [ 0.01320581  0.01947901  0.01923556  0.01538399]\n",
      "ucb [-0.00066682 -0.01815964 -0.0115522  -0.07879153]\n",
      "performance 0.375370761363 progress 0.175728694318\n",
      "task rewards [ 0.83593128  0.42596271  0.01667779  0.22291126]\n",
      "[chosen task]  0\n",
      "mu [ 0.04579744 -0.01036275  0.00227677 -0.07478616]\n",
      "sigma [ 0.01300551  0.0196189   0.0193333   0.01582354]\n",
      "ucb [ 0.04592749 -0.01016656  0.0024701  -0.07462793]\n",
      "performance 0.351632793668 progress -0.0237379676955\n",
      "task rewards [ 0.91574657  0.30689141  0.01496287  0.16893033]\n",
      "[chosen task]  0\n",
      "mu [ 0.03100261 -0.01016322 -0.00010113 -0.06964425]\n",
      "sigma [ 0.01286885  0.01971254  0.0193962   0.01636913]\n",
      "ucb [  3.11312968e-02  -9.96609954e-03   9.28346122e-05  -6.94805587e-02]\n",
      "performance 0.315687719286 progress -0.0359450743817\n",
      "task rewards [ 0.83717783  0.33813089  0.01488184  0.07256031]\n",
      "[chosen task]  0\n",
      "mu [ 0.01519433 -0.01016343 -0.00287099 -0.06360393]\n",
      "sigma [ 0.01278498  0.01977398  0.01943552  0.01696709]\n",
      "ucb [ 0.01532218 -0.00996569 -0.00267663 -0.06343426]\n",
      "performance 0.313019688956 progress -0.00266803033\n",
      "task rewards [ 0.86709742  0.29754042  0.01488184  0.07255907]\n",
      "[chosen task]  0\n",
      "mu [ 0.00967379 -0.00900449 -0.00307784 -0.05692117]\n",
      "sigma [ 0.01274083  0.01981388  0.01945962  0.01756585]\n",
      "ucb [ 0.0098012  -0.00880636 -0.00288325 -0.05674552]\n",
      "performance 0.28153007486 progress -0.0314896140956\n",
      "task rewards [ 0.73964609  0.29915216  0.01353435  0.07378771]\n",
      "[chosen task]  0\n",
      "mu [-0.00190365 -0.00875812 -0.00504411 -0.04997446]\n",
      "sigma [ 0.0127229   0.01983976  0.01947423  0.01812299]\n",
      "ucb [-0.00177642 -0.00855972 -0.00484937 -0.04979323]\n",
      "performance 0.287305385336 progress 0.0057753104759\n",
      "task rewards [ 0.75629326  0.28360736  0.01351699  0.09580393]\n",
      "[chosen task]  0\n",
      "mu [-0.00262142 -0.00733601 -0.0043081  -0.0429774 ]\n",
      "sigma [ 0.01271921  0.0198566   0.01948299  0.01860934]\n",
      "ucb [-0.00249423 -0.00713744 -0.00411327 -0.04279131]\n",
      "performance 0.330581623937 progress 0.0432762386006\n",
      "task rewards [ 0.9254762   0.28682594  0.01384888  0.09617548]\n",
      "[chosen task]  0\n",
      "mu [ 0.00615672 -0.00491533 -0.00121984 -0.03618847]\n",
      "sigma [ 0.01272089  0.01986762  0.01948813  0.01901006]\n",
      "ucb [ 0.00628393 -0.00471666 -0.00102496 -0.03599837]\n",
      "performance 0.323537858936 progress -0.00704376500107\n",
      "task rewards [ 0.88077367  0.25358864  0.06334717  0.09644195]\n",
      "[chosen task]  0\n",
      "mu [ 0.00209243 -0.00427537 -0.00165252 -0.02992061]\n",
      "sigma [ 0.01272278  0.01987483  0.01949103  0.01932293]\n",
      "ucb [ 0.00221966 -0.00407662 -0.00145761 -0.02972739]\n",
      "performance 0.313714969432 progress -0.00982288950409\n",
      "task rewards [ 0.80218136  0.2850395   0.06469084  0.10294817]\n",
      "[chosen task]  0\n",
      "mu [-0.00175675 -0.00378413 -0.00214931 -0.02425606]\n",
      "sigma [ 0.01272296  0.01987951  0.01949256  0.01955505]\n",
      "ucb [-0.00162952 -0.00358534 -0.00195438 -0.0240605 ]\n",
      "performance 0.357113529783 progress 0.0433985603518\n",
      "task rewards [ 0.86266548  0.35360785  0.0145222   0.19765859]\n",
      "[chosen task]  0\n",
      "mu [ 0.00794796 -0.00176883  0.00082226 -0.01921712]\n",
      "sigma [ 0.01272154  0.0198825   0.01949329  0.01971904]\n",
      "ucb [ 0.00807517 -0.00157     0.00101719 -0.01901993]\n",
      "performance 0.349141124595 progress -0.00797240518823\n",
      "task rewards [ 0.86219576  0.30987955  0.0268306   0.19765859]\n",
      "[chosen task]  0\n",
      "mu [ 0.00424829 -0.00157054  0.00017255 -0.0149697 ]\n",
      "sigma [ 0.01271948  0.01988437  0.0194936   0.01982951]\n",
      "ucb [ 0.00437549 -0.0013717   0.00036748 -0.0147714 ]\n",
      "performance 0.39521073472 progress 0.046069610125\n",
      "task rewards [ 0.86219576  0.5000535   0.02093508  0.19765859]\n",
      "[chosen task]  0\n",
      "mu [ 0.013916    0.00016125  0.00297321 -0.01137187]\n",
      "sigma [ 0.01271767  0.01988552  0.01949372  0.01990058]\n",
      "ucb [ 0.01404318  0.0003601   0.00316814 -0.01117287]\n",
      "performance 0.39521073472 progress 0.0\n",
      "task rewards [ 0.86219576  0.5000535   0.02093508  0.19765859]\n",
      "[chosen task]  0\n",
      "mu [ 0.0111159   0.00022778  0.00242771 -0.00850333]\n",
      "sigma [ 0.01271655  0.01988621  0.01949377  0.01994426]\n",
      "ucb [ 0.01124306  0.00042664  0.00262265 -0.00830389]\n",
      "performance 0.360088111043 progress -0.0351226236769\n",
      "task rewards [ 0.85452387  0.36950356  0.01865718  0.19766783]\n",
      "[chosen task]  0\n",
      "mu [ 0.00015115 -0.00081727 -0.00031782 -0.0062739 ]\n",
      "sigma [ 0.01271611  0.01988661  0.01949381  0.01996993]\n",
      "ucb [ 0.00027831 -0.0006184  -0.00012288 -0.0060742 ]\n",
      "performance 0.340122819768 progress -0.0199652912756\n",
      "task rewards [ 0.78155836  0.36359634  0.01766875  0.19766783]\n",
      "[chosen task]  1\n",
      "mu [-0.00562365 -0.00129409 -0.00173301 -0.00453722]\n",
      "sigma [ 0.01271609  0.01988683  0.01949385  0.01998438]\n",
      "ucb [-0.00549649 -0.00109522 -0.00153807 -0.00433738]\n",
      "performance 0.359543824218 progress 0.0194210044503\n",
      "task rewards [ 0.78809866  0.4006128   0.24147649  0.00798735]\n",
      "[chosen task]  1\n",
      "mu [-0.00647405  0.00893242  0.00727039 -0.00193242]\n",
      "sigma [ 0.01341877  0.01507513  0.01557582  0.01991644]\n",
      "ucb [-0.00633987  0.00908317  0.00742615 -0.00173326]\n",
      "performance 0.358346510688 progress -0.00119731353018\n",
      "task rewards [ 0.79890425  0.57929614  0.04262672  0.01255893]\n",
      "[chosen task]  1\n",
      "mu [-0.00757671  0.00520621  0.00368337 -0.00142229]\n",
      "sigma [ 0.01422242  0.01362346  0.0144157   0.0198975 ]\n",
      "ucb [-0.00743448  0.00534244  0.00382752 -0.00122331]\n",
      "performance 0.331189580492 progress -0.0271569301956\n",
      "task rewards [ 0.36077432  0.63957271  0.30357567  0.02083563]\n",
      "[chosen task]  3\n",
      "mu [-0.0088494  -0.00417478 -0.00500814 -0.00189184]\n",
      "sigma [ 0.01508144  0.01306144  0.01398666  0.01989056]\n",
      "ucb [-0.00869859 -0.00404417 -0.00486827 -0.00169294]\n",
      "performance 0.379894268394 progress 0.0487046879017\n",
      "task rewards [ 0.75813129  0.35207821  0.074992    0.33437558]\n",
      "[chosen task]  3\n",
      "mu [-0.0092445  -0.00377237 -0.00632722  0.02344321]\n",
      "sigma [ 0.01595233  0.01367331  0.01453745  0.01507604]\n",
      "ucb [-0.00908497 -0.00363564 -0.00618184  0.02359397]\n",
      "performance 0.31781170261 progress -0.062082565784\n",
      "task rewards [ 0.5385779   0.35181172  0.05272679  0.32813041]\n",
      "[chosen task]  1\n",
      "mu [-0.00921642 -0.00582404 -0.00629505 -0.00606927]\n",
      "sigma [ 0.01678268  0.01444348  0.01522098  0.01362437]\n",
      "ucb [-0.00904859 -0.00567961 -0.00614284 -0.00593302]\n",
      "performance 0.278784214567 progress -0.039027488043\n",
      "task rewards [ 0.53070704  0.48098833  0.02182057  0.08162092]\n",
      "[chosen task]  3\n",
      "mu [-0.01018704 -0.01722231 -0.01671818 -0.00742909]\n",
      "sigma [ 0.01751177  0.01371112  0.01461769  0.01410019]\n",
      "ucb [-0.01001192 -0.0170852  -0.016572   -0.00728809]\n",
      "performance 0.353728890993 progress 0.074944676426\n",
      "task rewards [ 0.48395411  0.43085669  0.02140242  0.47870235]\n",
      "[chosen task]  3\n",
      "mu [-0.00971963 -0.01612016 -0.01723284  0.01731073]\n",
      "sigma [ 0.01815314  0.01443259  0.01525268  0.01341872]\n",
      "ucb [-0.0095381  -0.01597584 -0.01708032  0.01744491]\n",
      "performance 0.360576018773 progress 0.00684712777976\n",
      "task rewards [ 0.34057843  0.39303939  0.0252332   0.68345306]\n",
      "[chosen task]  3\n",
      "mu [-0.00899802 -0.01628452 -0.01711402  0.0148242 ]\n",
      "sigma [ 0.0186775   0.01520183  0.01592518  0.01309137]\n",
      "ucb [-0.00881125 -0.0161325  -0.01695477  0.01495511]\n",
      "performance 0.349951748954 progress -0.0106242698188\n",
      "task rewards [ 0.21590418  0.39303939  0.03011064  0.76075279]\n",
      "[chosen task]  3\n",
      "mu [-0.00812572 -0.01641508 -0.01667201  0.00813322]\n",
      "sigma [ 0.01908636  0.01597677  0.01659964  0.01292724]\n",
      "ucb [-0.00793486 -0.01625531 -0.01650601  0.0082625 ]\n",
      "performance 0.315157227987 progress -0.0347945209674\n",
      "task rewards [ 0.21605671  0.39303939  0.02968394  0.62184887]\n",
      "[chosen task]  3\n",
      "mu [-0.00718152 -0.01672017 -0.01607182 -0.0033278 ]\n",
      "sigma [ 0.0193909   0.01671993  0.01724447  0.01284152]\n",
      "ucb [-0.00698761 -0.01655297 -0.01589938 -0.00319938]\n",
      "performance 0.348164045679 progress 0.0330068176921\n",
      "task rewards [ 0.21404178  0.39303939  0.02505752  0.7605175 ]\n",
      "[chosen task]  3\n",
      "mu [-0.00614544 -0.01459592 -0.01445468  0.00400558]\n",
      "sigma [ 0.01960792  0.01740085  0.01783407  0.01279402]\n",
      "ucb [-0.00594936 -0.01442191 -0.01427634  0.00413352]\n",
      "performance 0.353190550069 progress 0.00502650439072\n",
      "task rewards [ 0.20763471  0.39303939  0.07391607  0.73817203]\n",
      "[chosen task]  3\n",
      "mu [-0.00515996 -0.01312899 -0.01294563  0.00358923]\n",
      "sigma [ 0.01975612  0.01799796  0.01835041  0.01276599]\n",
      "ucb [-0.0049624  -0.01294901 -0.01276212  0.00371689]\n",
      "performance 0.356310341654 progress 0.0031197915843\n",
      "task rewards [ 0.31751849  0.39303939  0.02618554  0.68849795]\n",
      "[chosen task]  3\n",
      "mu [-0.00423883 -0.01156177 -0.01133729  0.00289555]\n",
      "sigma [ 0.01985325  0.01849943  0.01878367  0.01274885]\n",
      "ucb [-0.0040403  -0.01137678 -0.01114946  0.00302303]\n",
      "performance 0.33716357473 progress -0.0191467669237\n",
      "task rewards [ 0.27109469  0.41693486  0.02548064  0.63514412]\n",
      "[chosen task]  3\n",
      "mu [-0.00343392 -0.01059554 -0.00996725 -0.00287438]\n",
      "sigma [ 0.01991446  0.01890282  0.01913202  0.01273834]\n",
      "ucb [-0.00323478 -0.01040651 -0.00977593 -0.00274699]\n",
      "performance 0.336811523448 progress -0.000352051281909\n",
      "task rewards [ 0.25996831  0.41693486  0.02494703  0.64539589]\n",
      "[chosen task]  0\n",
      "mu [-0.0027077  -0.00896702 -0.00836465 -0.00306764]\n",
      "sigma [ 0.01995161  0.01921361  0.01940036  0.01273192]\n",
      "ucb [-0.00250818 -0.00877489 -0.00817065 -0.00294033]\n",
      "performance 0.401342002476 progress 0.0645304790278\n",
      "task rewards [ 0.51998273  0.5944268   0.05191432  0.43904416]\n",
      "[chosen task]  0\n",
      "mu [ 0.03114956 -0.00357264  0.00167177 -0.00352799]\n",
      "sigma [ 0.01509599  0.01938672  0.01927644  0.01344427]\n",
      "ucb [ 0.03130052 -0.00337877  0.00186453 -0.00339355]\n",
      "performance 0.460828207057 progress 0.0594862045815\n",
      "task rewards [ 0.77567492  0.58063744  0.03020374  0.45679673]\n",
      "[chosen task]  0\n",
      "mu [ 0.04035598 -0.00112487  0.00530212 -0.00379844]\n",
      "sigma [ 0.01363152  0.01953849  0.0193153   0.01425588]\n",
      "ucb [ 0.0404923  -0.00092948  0.00549527 -0.00365588]\n",
      "performance 0.422463136425 progress -0.0383650706319\n",
      "task rewards [ 0.67806013  0.56719951  0.0314168   0.41317611]\n",
      "[chosen task]  0\n",
      "mu [ 0.01728083 -0.00278052  0.00032931 -0.00395149]\n",
      "sigma [ 0.01306379  0.01965114  0.01936909  0.01512269]\n",
      "ucb [ 0.01741147 -0.00258401  0.000523   -0.00380026]\n",
      "performance 0.386065676894 progress -0.0363974595311\n",
      "task rewards [ 0.56575407  0.53020443  0.03326959  0.41503462]\n",
      "[chosen task]  0\n",
      "mu [ 0.00139238 -0.0037338  -0.0029333  -0.00392649]\n",
      "sigma [ 0.01285672  0.01973068  0.01941464  0.01599456]\n",
      "ucb [ 0.00152095 -0.00353649 -0.00273915 -0.00376654]\n",
      "performance 0.452569246848 progress 0.0665035699536\n",
      "task rewards [ 0.83716414  0.53020443  0.02939303  0.4135154 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.01414406 -0.00126144  0.00121875 -0.00365313]\n",
      "sigma [ 0.01280197  0.01978517  0.01944802  0.01682337]\n",
      "ucb [ 0.01427208 -0.00106358  0.00141323 -0.0034849 ]\n",
      "performance 0.455997971519 progress 0.00342872467106\n",
      "task rewards [ 0.85087903  0.53020443  0.02939303  0.4135154 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00978671 -0.00109432  0.00069477 -0.00335184]\n",
      "sigma [ 0.01279744  0.01982164  0.01946999  0.01757   ]\n",
      "ucb [ 0.00991468 -0.00089611  0.00088947 -0.00317614]\n",
      "performance 0.452605838109 progress -0.00339213341021\n",
      "task rewards [ 0.85055675  0.52861879  0.02734532  0.40390249]\n",
      "[chosen task]  0\n",
      "mu [ 0.0046955  -0.00115716 -0.00015264 -0.00299205]\n",
      "sigma [ 0.01279636  0.01984555  0.0194829   0.01820872]\n",
      "ucb [  4.82346846e-03  -9.58700211e-04   4.21889618e-05  -2.80996242e-03]\n",
      "performance 0.376921376172 progress -0.0756844619368\n",
      "task rewards [ 0.6611561   0.36817868  0.01709297  0.46125775]\n",
      "[chosen task]  3\n",
      "mu [-0.01667538 -0.00337318 -0.00540772 -0.00268427]\n",
      "sigma [ 0.01278508  0.01986099  0.01948949  0.01872847]\n",
      "ucb [-0.01654753 -0.00317457 -0.00521283 -0.00249699]\n",
      "performance 0.390972225353 progress 0.014050849181\n",
      "task rewards [ 0.69963309  0.39417432  0.02143044  0.44865105]\n",
      "[chosen task]  3\n",
      "mu [-0.01955616 -0.0024008  -0.00549079  0.00562515]\n",
      "sigma [ 0.01350713  0.01981785  0.0195338   0.01494889]\n",
      "ucb [-0.01942109 -0.00220262 -0.00529545  0.00577464]\n",
      "performance 0.401225389859 progress 0.0102531645056\n",
      "task rewards [ 0.53004524  0.35214793  0.03099597  0.69171242]\n",
      "[chosen task]  3\n",
      "mu [-0.02146071 -0.00218847 -0.00570459  0.00749361]\n",
      "sigma [ 0.01431939  0.01981191  0.0195886   0.01362169]\n",
      "ucb [-0.02131751 -0.00199035 -0.0055087   0.00762982]\n",
      "performance 0.417929751658 progress 0.0167043617989\n",
      "task rewards [ 0.53855776  0.35214793  0.03222822  0.74878509]\n",
      "[chosen task]  3\n",
      "mu [-0.02237743 -0.00182088 -0.00567818  0.01013851]\n",
      "sigma [ 0.01517982  0.01981744  0.01964774  0.01305802]\n",
      "ucb [-0.02222563 -0.00162271 -0.0054817   0.01026909]\n",
      "performance 0.407200217836 progress -0.0107295338214\n",
      "task rewards [ 0.64616613  0.35214793  0.01866234  0.61182447]\n",
      "[chosen task]  3\n",
      "mu [-0.0224059  -0.00237825 -0.00584757  0.00481263]\n",
      "sigma [ 0.01604143  0.01982772  0.01970735  0.01283442]\n",
      "ucb [-0.02224548 -0.00217997 -0.0056505   0.00494097]\n",
      "performance 0.37642732502 progress -0.030772892816\n",
      "task rewards [ 0.63505696  0.29850281  0.01890695  0.55324258]\n",
      "[chosen task]  1\n",
      "mu [-0.02166285 -0.00334863 -0.00603071 -0.00434046]\n",
      "sigma [ 0.016859    0.01983953  0.01976409  0.0127709 ]\n",
      "ucb [-0.02149426 -0.00315024 -0.00583306 -0.00421275]\n",
      "performance 0.440652301542 progress 0.0642249765214\n",
      "task rewards [ 0.53888049  0.67695433  0.05072431  0.49605008]\n",
      "[chosen task]  1\n",
      "mu [-0.01722886  0.02994759  0.02490281 -0.00418614]\n",
      "sigma [ 0.01755559  0.01506855  0.01575531  0.0134951 ]\n",
      "ucb [-0.0170533   0.03009828  0.02506036 -0.00405119]\n",
      "performance 0.423405405907 progress -0.0172468956351\n",
      "task rewards [ 0.57734127  0.41377453  0.15266661  0.54983922]\n",
      "[chosen task]  1\n",
      "mu [-0.01698217  0.0131155   0.00974457 -0.00589292]\n",
      "sigma [ 0.01816619  0.01362305  0.01455116  0.01433488]\n",
      "ucb [-0.01680051  0.01325173  0.00989008 -0.00574957]\n",
      "performance 0.455801360452 progress 0.0323959545457\n",
      "task rewards [ 0.63968357  0.53263258  0.06672308  0.58416622]\n",
      "[chosen task]  1\n",
      "mu [-0.01429077  0.01728902  0.01396172 -0.00615358]\n",
      "sigma [ 0.01866616  0.01306203  0.01409018  0.01522578]\n",
      "ucb [-0.01410411  0.01741964  0.01410262 -0.00600132]\n",
      "performance 0.460122336685 progress 0.00432097623315\n",
      "task rewards [ 0.63236241  0.45166303  0.0593069   0.697157  ]\n",
      "[chosen task]  1\n",
      "mu [-0.01251486  0.01280984  0.01019866 -0.00681009]\n",
      "sigma [ 0.01905446  0.01285693  0.01392643  0.01610667]\n",
      "ucb [-0.01232431  0.01293841  0.01033793 -0.00664903]\n",
      "performance 0.453351495833 progress -0.00677084085209\n",
      "task rewards [ 0.48798431  0.61953634  0.0798058   0.62607953]\n",
      "[chosen task]  1\n",
      "mu [-0.01102013  0.00649107  0.00471889 -0.00744065]\n",
      "sigma [ 0.01934139  0.01280211  0.013887    0.01692651]\n",
      "ucb [-0.01082672  0.00661909  0.00485776 -0.00727139]\n",
      "performance 0.48814890163 progress 0.0347974057966\n",
      "task rewards [ 0.37448204  0.79540964  0.15953315  0.62317078]\n",
      "[chosen task]  1\n",
      "mu [-0.00821044  0.01146226  0.0096007  -0.00647833]\n",
      "sigma [ 0.01954336  0.012797    0.01388774  0.01764909]\n",
      "ucb [-0.00801501  0.01159023  0.00973957 -0.00630184]\n",
      "performance 0.50651804536 progress 0.0183691437297\n",
      "task rewards [ 0.40456269  0.8089468   0.15595972  0.65660297]\n",
      "[chosen task]  1\n",
      "mu [-0.00620993  0.0118831   0.01024476 -0.00585418]\n",
      "sigma [ 0.01967895  0.01279558  0.01389039  0.0182547 ]\n",
      "ucb [-0.00601314  0.01201105  0.01038367 -0.00567164]\n",
      "performance 0.475847332085 progress -0.0306707132748\n",
      "task rewards [ 0.40456269  0.87004003  0.16240938  0.46637723]\n",
      "[chosen task]  1\n",
      "mu [ -5.96908405e-03   4.69807165e-04  -4.85473555e-05  -6.60481911e-03]\n",
      "sigma [ 0.01976585  0.01278432  0.0138839   0.01873867]\n",
      "ucb [ -5.77142560e-03   5.97650363e-04   9.02916403e-05  -6.41743236e-03]\n",
      "performance 0.501099800847 progress 0.0252524687625\n",
      "task rewards [ 0.52170258  0.87004003  0.16240938  0.45024721]\n",
      "[chosen task]  1\n",
      "mu [-0.0040151   0.00461722  0.00392948 -0.00524037]\n",
      "sigma [ 0.01981909  0.01276578  0.01387062  0.01910814]\n",
      "ucb [-0.00381691  0.00474488  0.00406819 -0.00504929]\n",
      "performance 0.501099800847 progress 0.0\n",
      "task rewards [ 0.52170258  0.87004003  0.16240938  0.45024721]\n",
      "[chosen task]  1\n",
      "mu [-0.00312245  0.0024419   0.00204937 -0.00466899]\n",
      "sigma [ 0.01985033  0.01274683  0.01385645  0.01937791]\n",
      "ucb [-0.00292395  0.00256936  0.00218794 -0.00447521]\n",
      "performance 0.485026858509 progress -0.0160729423386\n",
      "task rewards [ 0.53771444  0.81979272  0.16240938  0.4201909 ]\n",
      "[chosen task]  2\n",
      "mu [-0.00286681 -0.00292014 -0.00279739 -0.00451705]\n",
      "sigma [ 0.01986793  0.01273249  0.01384572  0.01956645]\n",
      "ucb [-0.00266813 -0.00279282 -0.00265893 -0.00432139]\n",
      "performance 0.330330786713 progress -0.154696071795\n",
      "task rewards [ 0.30353421  0.41673813  0.16348235  0.43756846]\n",
      "[chosen task]  3\n",
      "mu [-0.02223883 -0.03441529 -0.04837316 -0.0008521 ]\n",
      "sigma [ 0.01964954  0.01288294  0.0132472   0.01969857]\n",
      "ucb [-0.02204234 -0.03428646 -0.04824069 -0.00065512]\n",
      "performance 0.427171820708 progress 0.0968410339951\n",
      "task rewards [ 0.19057964  0.48461189  0.17018785  0.8633079 ]\n",
      "[chosen task]  3\n",
      "mu [-0.02161604 -0.03450556 -0.0509184   0.04722331]\n",
      "sigma [ 0.01967228  0.01359963  0.01385575  0.01506364]\n",
      "ucb [-0.02141931 -0.03436956 -0.05077984  0.04737394]\n",
      "performance 0.39379987526 progress -0.0333719454481\n",
      "task rewards [ 0.34573462  0.44747098  0.16004489  0.62194902]\n",
      "[chosen task]  3\n",
      "mu [-0.02061202 -0.03771087 -0.05125343  0.01873375]\n",
      "sigma [ 0.01970281  0.01441205  0.01457738  0.01362533]\n",
      "ucb [-0.02041499 -0.03756675 -0.05110766  0.01887   ]\n",
      "performance 0.475192867608 progress 0.0813929923476\n",
      "task rewards [ 0.22517207  0.69770954  0.18078361  0.79710625]\n",
      "[chosen task]  3\n",
      "mu [-0.01932582 -0.03646761 -0.05006054  0.03430188]\n",
      "sigma [ 0.01973976  0.01527063  0.0153679   0.01305945]\n",
      "ucb [-0.01912842 -0.03631491 -0.04990686  0.03443248]\n",
      "performance 0.475346160845 progress 0.000153293237381\n",
      "task rewards [ 0.22744593  0.71433681  0.17927733  0.78032457]\n",
      "[chosen task]  3\n",
      "mu [-0.01781216 -0.0363536  -0.04804996  0.02397248]\n",
      "sigma [ 0.01978047  0.01612428  0.01617667  0.01285097]\n",
      "ucb [-0.01761436 -0.03619236 -0.04788819  0.02410099]\n",
      "performance 0.495912183354 progress 0.0205660225091\n",
      "task rewards [ 0.22765669  0.71433681  0.22610269  0.81555254]\n",
      "[chosen task]  3\n",
      "mu [-0.01610184 -0.03457534 -0.04483007  0.02050351]\n",
      "sigma [ 0.01982183  0.01692609  0.01695441  0.01279605]\n",
      "ucb [-0.01590362 -0.03440608 -0.04466052  0.02063147]\n",
      "performance 0.510714425149 progress 0.0148022417947\n",
      "task rewards [ 0.29336056  0.6418088   0.269311    0.83837734]\n",
      "[chosen task]  3\n",
      "mu [-0.0142784  -0.03211305 -0.04086786  0.01627852]\n",
      "sigma [ 0.01986099  0.01763975  0.01766053  0.01279281]\n",
      "ucb [-0.01407979 -0.03193666 -0.04069126  0.01640645]\n",
      "performance 0.513376054758 progress 0.0026616296085\n",
      "task rewards [ 0.32048619  0.56569915  0.32894154  0.83837734]\n",
      "[chosen task]  3\n",
      "mu [-0.01242341 -0.02936801 -0.03651062  0.0100569 ]\n",
      "sigma [ 0.01989577  0.01824313  0.01826782  0.01279354]\n",
      "ucb [-0.01222445 -0.02918557 -0.03632794  0.01018483]\n",
      "performance 0.527702669324 progress 0.0143266145669\n",
      "task rewards [ 0.32048619  0.57424578  0.37987603  0.83620268]\n",
      "[chosen task]  3\n",
      "mu [-0.01058149 -0.02578289 -0.03170967  0.00811685]\n",
      "sigma [ 0.01992491  0.01872869  0.01876379  0.01278374]\n",
      "ucb [-0.01038224 -0.02559561 -0.03152203  0.00824468]\n",
      "performance 0.528337560407 progress 0.000634891082393\n",
      "task rewards [ 0.40702817  0.56569915  0.36067211  0.77995081]\n",
      "[chosen task]  3\n",
      "mu [-0.00884431 -0.02243341 -0.02706001  0.00379453]\n",
      "sigma [ 0.01994803  0.01910117  0.01914913  0.01276578]\n",
      "ucb [-0.00864483 -0.0222424  -0.02686851  0.00392219]\n",
      "performance 0.544685933286 progress 0.0163483728795\n",
      "task rewards [ 0.43792491  0.55783471  0.36369043  0.81929368]\n",
      "[chosen task]  3\n",
      "mu [-0.00722436 -0.01855297 -0.02237432  0.00456627]\n",
      "sigma [ 0.01996543  0.0193739   0.01943438  0.01274684]\n",
      "ucb [-0.00702471 -0.01835923 -0.02217997  0.00469374]\n",
      "performance 0.543816192418 progress -0.000869740868532\n",
      "task rewards [ 0.43792491  0.55071948  0.35652149  0.8300989 ]\n",
      "[chosen task]  3\n",
      "mu [-0.0057974  -0.01539812 -0.01826121  0.00172635]\n",
      "sigma [ 0.01997789  0.01956466  0.01963581  0.01273232]\n",
      "ucb [-0.00559762 -0.01520247 -0.01806486  0.00185367]\n",
      "performance 0.506612190388 progress -0.0372040020301\n",
      "task rewards [ 0.39803162  0.47330985  0.32500839  0.8300989 ]\n",
      "[chosen task]  0\n",
      "mu [-0.00460077 -0.01356474 -0.01501678 -0.00875328]\n",
      "sigma [ 0.01998639  0.01969224  0.01977162  0.01272394]\n",
      "ucb [-0.00440091 -0.01336782 -0.01481907 -0.00862604]\n",
      "performance 0.567816510636 progress 0.0612043202478\n",
      "task rewards [ 0.68691074  0.54961887  0.28959025  0.74514618]\n",
      "[chosen task]  0\n",
      "mu [ 0.0290075  -0.0070835  -0.00338005 -0.01019371]\n",
      "sigma [ 0.01509798  0.01971361  0.01953034  0.01343294]\n",
      "ucb [ 0.02915848 -0.00688636 -0.00318475 -0.01005938]\n",
      "performance 0.480970133698 progress -0.0868463769379\n",
      "task rewards [ 0.86304436  0.70618658  0.06286523  0.29178436]\n",
      "[chosen task]  1\n",
      "mu [-0.01055972 -0.00983582 -0.01128097 -0.0111511 ]\n",
      "sigma [ 0.01363168  0.01975301  0.01948308  0.01424301]\n",
      "ucb [-0.0104234  -0.00963829 -0.01108614 -0.01100866]\n",
      "performance 0.432438372726 progress -0.0485317609712\n",
      "task rewards [ 0.44609422  0.57425387  0.31902547  0.39037993]\n",
      "[chosen task]  0\n",
      "mu [-0.01187049 -0.02708838 -0.02667518 -0.0126014 ]\n",
      "sigma [ 0.01410047  0.01505753  0.01559798  0.01509347]\n",
      "ucb [-0.01172948 -0.02693781 -0.0265192  -0.01245046]\n",
      "performance 0.518239104852 progress 0.0858007321252\n",
      "task rewards [ 0.7731291   0.66226104  0.20283232  0.43473397]\n",
      "[chosen task]  0\n",
      "mu [ 0.01791443 -0.02294889 -0.01812803 -0.01250233]\n",
      "sigma [ 0.01341863  0.01534715  0.01581155  0.01596521]\n",
      "ucb [ 0.01804862 -0.02279542 -0.01796992 -0.01234268]\n",
      "performance 0.573465978755 progress 0.0552268739033\n",
      "task rewards [ 0.79866589  0.66226104  0.31986422  0.51307276]\n",
      "[chosen task]  0\n",
      "mu [ 0.02898339 -0.0198753  -0.01347352 -0.01196825]\n",
      "sigma [ 0.01309166  0.01578466  0.01615994  0.01679557]\n",
      "ucb [ 0.02911431 -0.01971745 -0.01331192 -0.01180029]\n",
      "performance 0.586376266433 progress 0.0129102876776\n",
      "task rewards [ 0.75460607  0.72194244  0.34001559  0.52894097]\n",
      "[chosen task]  0\n",
      "mu [ 0.02560299 -0.0179511  -0.01212122 -0.01113077]\n",
      "sigma [ 0.01292792  0.01632469  0.01659798  0.01754491]\n",
      "ucb [ 0.02573227 -0.01778785 -0.01195524 -0.01095532]\n",
      "performance 0.627553456719 progress 0.0411771902865\n",
      "task rewards [ 0.80301613  0.81133999  0.34001559  0.55584212]\n",
      "[chosen task]  0\n",
      "mu [ 0.0291907  -0.0153085  -0.00912712 -0.01005043]\n",
      "sigma [ 0.01284234  0.01691471  0.01707893  0.01818702]\n",
      "ucb [ 0.02931912 -0.01513936 -0.00895633 -0.00986856]\n",
      "performance 0.579843996697 progress -0.0477094600223\n",
      "task rewards [ 0.60967814  0.81133999  0.34081048  0.55754738]\n",
      "[chosen task]  0\n",
      "mu [ 0.00978099 -0.01524682 -0.01198361 -0.00892984]\n",
      "sigma [ 0.01279473  0.01750414  0.01755962  0.01871045]\n",
      "ucb [ 0.00990894 -0.01507178 -0.01180801 -0.00874274]\n",
      "performance 0.537801120492 progress -0.0420428762052\n",
      "task rewards [ 0.61846214  0.81133999  0.16385498  0.55754738]\n",
      "[chosen task]  0\n",
      "mu [-0.00520698 -0.01483846 -0.01388815 -0.00775177]\n",
      "sigma [ 0.01276647  0.01805146  0.01800549  0.01911692]\n",
      "ucb [-0.00507931 -0.01465795 -0.01370809 -0.0075606 ]\n",
      "performance 0.584218255251 progress 0.0464171347589\n",
      "task rewards [ 0.81238665  0.81133999  0.17179599  0.54135038]\n",
      "[chosen task]  0\n",
      "mu [ 0.00387935 -0.01159111 -0.00960841 -0.0064799 ]\n",
      "sigma [ 0.01274908  0.01852838  0.01839339  0.019418  ]\n",
      "ucb [ 0.00400684 -0.01140582 -0.00942447 -0.00628572]\n",
      "performance 0.590636893338 progress 0.00641863808751\n",
      "task rewards [ 0.85937123  0.81133999  0.17179599  0.52004036]\n",
      "[chosen task]  0\n",
      "mu [ 0.00261657 -0.00976255 -0.00818365 -0.00533294]\n",
      "sigma [ 0.01273841  0.01892069  0.01871195  0.01963094]\n",
      "ucb [ 0.00274395 -0.00957334 -0.00799653 -0.00513663]\n",
      "performance 0.600671639693 progress 0.0100347463549\n",
      "task rewards [ 0.77609157  0.72194244  0.17175403  0.73289852]\n",
      "[chosen task]  0\n",
      "mu [ 0.00286307 -0.00791805 -0.00651964 -0.00428784]\n",
      "sigma [ 0.01273192  0.01922655  0.01895992  0.01977485]\n",
      "ucb [ 0.00299039 -0.00772578 -0.00633004 -0.00409009]\n",
      "performance 0.66786886001 progress 0.0671972203168\n",
      "task rewards [ 0.85255823  0.72194244  0.36407625  0.73289852]\n",
      "[chosen task]  0\n",
      "mu [ 0.01705923 -0.004512   -0.00133601 -0.0033028 ]\n",
      "sigma [ 0.01272783  0.01945322  0.01914341  0.01986786]\n",
      "ucb [ 0.0171865  -0.00431747 -0.00114458 -0.00310412]\n",
      "performance 0.655692697586 progress -0.012176162424\n",
      "task rewards [ 0.8372495   0.72194244  0.33068033  0.73289852]\n",
      "[chosen task]  0\n",
      "mu [ 0.01037623 -0.00396261 -0.00188452 -0.00256181]\n",
      "sigma [ 0.01272495  0.0196132   0.01927275  0.01992538]\n",
      "ucb [ 0.01050348 -0.00376648 -0.00169179 -0.00236255]\n",
      "performance 0.644891627216 progress -0.0108010703697\n",
      "task rewards [ 0.76677922  0.72194244  0.30876662  0.78207824]\n",
      "[chosen task]  0\n",
      "mu [ 0.00491396 -0.0034669  -0.00229219 -0.00194966]\n",
      "sigma [ 0.01272267  0.01972091  0.01935973  0.01995943]\n",
      "ucb [ 0.00504118 -0.00326969 -0.00209859 -0.00175007]\n",
      "performance 0.635675137559 progress -0.00921648965754\n",
      "task rewards [ 0.89752356  0.72194244  0.14115631  0.78207824]\n",
      "[chosen task]  0\n",
      "mu [ 0.00072021 -0.00301388 -0.00254149 -0.00145684]\n",
      "sigma [ 0.01272075  0.01979017  0.01941562  0.01997875]\n",
      "ucb [ 0.00084742 -0.00281598 -0.00234734 -0.00125705]\n",
      "performance 0.64080793198 progress 0.00513279442111\n",
      "task rewards [ 0.8980486   0.72194244  0.13501866  0.80822203]\n",
      "[chosen task]  0\n",
      "mu [ 0.00076149 -0.00221964 -0.00183751 -0.00105491]\n",
      "sigma [ 0.01271921  0.01983275  0.01944997  0.01998925]\n",
      "ucb [ 0.00088869 -0.00202131 -0.00164302 -0.00085501]\n",
      "performance 0.589934427206 progress -0.0508735047737\n",
      "task rewards [ 0.85427741  0.72194244  0.14115631  0.64236155]\n",
      "[chosen task]  3\n",
      "mu [-0.01219879 -0.00321227 -0.00470795 -0.00081086]\n",
      "sigma [ 0.01271809  0.0198578   0.01947019  0.01999472]\n",
      "ucb [-0.01207161 -0.00301369 -0.00451325 -0.00061091]\n",
      "performance 0.582772638334 progress -0.00716178887247\n",
      "task rewards [ 0.77382581  0.79481399  0.05998329  0.70246746]\n",
      "[chosen task]  1\n",
      "mu [-0.01363428 -0.00330077 -0.00481684 -0.00373277]\n",
      "sigma [ 0.01342773  0.01980775  0.01951932  0.01509879]\n",
      "ucb [-0.0135     -0.0031027  -0.00462165 -0.00358178]\n",
      "performance 0.580740652002 progress -0.00203198633182\n",
      "task rewards [ 0.77212209  0.72061451  0.1233813   0.7068447 ]\n",
      "[chosen task]  1\n",
      "mu [-0.01450472 -0.00241833 -0.00416435 -0.00343728]\n",
      "sigma [ 0.01422607  0.01506082  0.01561122  0.01536378]\n",
      "ucb [-0.01436246 -0.00226772 -0.00400824 -0.00328364]\n",
      "performance 0.561024986822 progress -0.0197156651796\n",
      "task rewards [ 0.63711524  0.86660424  0.16950732  0.57087314]\n",
      "[chosen task]  3\n",
      "mu [-0.01524389 -0.00806735 -0.00940147 -0.00360297]\n",
      "sigma [ 0.0150833   0.0136194   0.01444488  0.01579402]\n",
      "ucb [-0.01509306 -0.00793116 -0.00925702 -0.00344503]\n",
      "performance 0.614023275286 progress 0.0529982884639\n",
      "task rewards [ 0.56967149  0.79954084  0.25181692  0.83506385]\n",
      "[chosen task]  3\n",
      "mu [-0.01514644 -0.00660144 -0.00944514  0.01808313]\n",
      "sigma [ 0.0159539   0.0140952   0.01488466  0.01407815]\n",
      "ucb [-0.01498691 -0.00646049 -0.0092963   0.01822391]\n",
      "performance 0.553742172313 progress -0.0602811029731\n",
      "task rewards [ 0.56967149  0.6202835   0.26448353  0.76053017]\n",
      "[chosen task]  3\n",
      "mu [-0.01457018 -0.00777233 -0.0089245  -0.00527225]\n",
      "sigma [ 0.01678395  0.01474275  0.01546746  0.01334644]\n",
      "ucb [-0.01440234 -0.00762491 -0.00876983 -0.00513879]\n",
      "performance 0.610839105993 progress 0.0570969336805\n",
      "task rewards [ 0.73117508  0.62276214  0.26765358  0.82176562]\n",
      "[chosen task]  3\n",
      "mu [-0.01359366 -0.00595679 -0.00816284  0.01088055]\n",
      "sigma [ 0.01753393  0.01549478  0.01613574  0.01300836]\n",
      "ucb [-0.01341832 -0.00580184 -0.00800148  0.01101064]\n",
      "performance 0.604719481903 progress -0.00611962409041\n",
      "task rewards [ 0.73117508  0.60780765  0.25812958  0.82176562]\n",
      "[chosen task]  3\n",
      "mu [-0.01237037 -0.0057587  -0.00753913  0.00683976]\n",
      "sigma [ 0.01817742  0.01628171  0.01682999  0.01285679]\n",
      "ucb [-0.01218859 -0.00559588 -0.00737083  0.00696832]\n",
      "performance 0.604022426345 progress -0.000697055557682\n",
      "task rewards [ 0.73277765  0.60780765  0.26297411  0.8125303 ]\n",
      "[chosen task]  3\n",
      "mu [-0.01096657 -0.005341   -0.00681201  0.00472345]\n",
      "sigma [ 0.01870263  0.01704164  0.01749747  0.01279478]\n",
      "ucb [-0.01077954 -0.00517059 -0.00663703  0.00485139]\n",
      "performance 0.540402876034 progress -0.0636195503116\n",
      "task rewards [ 0.56967149  0.52063713  0.25877258  0.8125303 ]\n",
      "[chosen task]  1\n",
      "mu [-0.00955345 -0.00670539 -0.00674966 -0.01226592]\n",
      "sigma [ 0.01911096  0.01772768  0.01809835  0.01277152]\n",
      "ucb [-0.00936234 -0.00652811 -0.00656868 -0.01213821]\n",
      "performance 0.659659657573 progress 0.119256781539\n",
      "task rewards [ 0.76691477  0.8729993   0.17166374  0.82706082]\n",
      "[chosen task]  1\n",
      "mu [-0.00105525  0.0502749   0.04626604 -0.01109135]\n",
      "sigma [ 0.01935872  0.01475811  0.01556169  0.01348691]\n",
      "ucb [-0.00086167  0.05042248  0.04642165 -0.01095648]\n",
      "performance 0.678852410953 progress 0.0191927533799\n",
      "task rewards [ 0.7648999   0.88840207  0.17902668  0.88308099]\n",
      "[chosen task]  1\n",
      "mu [-0.000926    0.04057619  0.03756576 -0.01263436]\n",
      "sigma [ 0.01954717  0.01359079  0.0145661   0.014302  ]\n",
      "ucb [-0.00073053  0.0407121   0.03771142 -0.01249134]\n",
      "performance 0.671302479477 progress -0.00754993147566\n",
      "task rewards [ 0.76221549  0.88840207  0.17902668  0.85556567]\n",
      "[chosen task]  1\n",
      "mu [-0.00148029  0.02643841  0.02472649 -0.01418224]\n",
      "sigma [ 0.01967782  0.01305979  0.01411369  0.01516707]\n",
      "ucb [-0.00128351  0.02656901  0.02486762 -0.01403057]\n",
      "performance 0.611634567203 progress -0.0596679122746\n",
      "task rewards [ 0.57823605  0.81991208  0.2709999   0.77739024]\n",
      "[chosen task]  2\n",
      "mu [-0.00338455  0.00274179  0.00303255 -0.0163588 ]\n",
      "sigma [ 0.01976359  0.01283305  0.01392082  0.01603014]\n",
      "ucb [-0.00318692  0.00287012  0.00317176 -0.0161985 ]\n",
      "performance 0.382250787833 progress -0.22938377937\n",
      "task rewards [ 0.31349349  0.3770226   0.15720877  0.68127829]\n",
      "[chosen task]  3\n",
      "mu [-0.03321715 -0.0482111  -0.06889418 -0.01441442]\n",
      "sigma [ 0.01959233  0.01292244  0.01326898  0.01685149]\n",
      "ucb [-0.03302123 -0.04808188 -0.06876149 -0.01424591]\n",
      "performance 0.476077837664 progress 0.0938270498308\n",
      "task rewards [ 0.4220489   0.47503814  0.22547255  0.78175176]\n",
      "[chosen task]  3\n",
      "mu [-0.03256652 -0.05087708 -0.07351086  0.03189436]\n",
      "sigma [ 0.01964245  0.01364736  0.01389078  0.01455641]\n",
      "ucb [-0.03237009 -0.0507406  -0.07337195  0.03203993]\n",
      "performance 0.491648087311 progress 0.0155702496476\n",
      "task rewards [ 0.39213608  0.54964972  0.24305478  0.78175176]\n",
      "[chosen task]  3\n",
      "mu [-0.03132719 -0.05493773 -0.07577881  0.02796373]\n",
      "sigma [ 0.01968896  0.01448194  0.01463751  0.01354529]\n",
      "ucb [-0.0311303  -0.05479291 -0.07563244  0.02809918]\n",
      "performance 0.529448089762 progress 0.0378000024506\n",
      "task rewards [ 0.57823605  0.4964758   0.24309107  0.79998944]\n",
      "[chosen task]  3\n",
      "mu [-0.02958847 -0.05643103 -0.07576534  0.03103703]\n",
      "sigma [ 0.01973474  0.01536369  0.01545249  0.01305269]\n",
      "ucb [-0.02939112 -0.05627739 -0.07561081  0.03116756]\n",
      "performance 0.545699539484 progress 0.0162514497221\n",
      "task rewards [ 0.57823605  0.44495691  0.28019252  0.87941268]\n",
      "[chosen task]  3\n",
      "mu [-0.02742921 -0.05662872 -0.07380761  0.02695063]\n",
      "sigma [ 0.01977999  0.01623247  0.01627699  0.0128283 ]\n",
      "ucb [-0.02723141 -0.0564664  -0.07364484  0.02707891]\n",
      "performance 0.541414438142 progress -0.00428510134204\n",
      "task rewards [ 0.57823605  0.45161206  0.25639696  0.87941268]\n",
      "[chosen task]  3\n",
      "mu [-0.02495329 -0.05558646 -0.07020275  0.01810614]\n",
      "sigma [ 0.01982339  0.01703794  0.01705884  0.01274901]\n",
      "ucb [-0.02475505 -0.05541608 -0.07003216  0.01823363]\n",
      "performance 0.539803849091 progress -0.0016105890508\n",
      "task rewards [ 0.57823605  0.45161206  0.24995461  0.87941268]\n",
      "[chosen task]  3\n",
      "mu [-0.02225441 -0.05283895 -0.0650485   0.01108198]\n",
      "sigma [ 0.01986322  0.01774459  0.01775857  0.01273845]\n",
      "ucb [-0.02205577 -0.05266151 -0.06487091  0.01120936]\n",
      "performance 0.553639521674 progress 0.013835672583\n",
      "task rewards [ 0.57823605  0.49155842  0.2663813   0.87838232]\n",
      "[chosen task]  3\n",
      "mu [-0.01943451 -0.0483323  -0.05858324  0.00889182]\n",
      "sigma [ 0.01989796  0.01833353  0.01835226  0.01274887]\n",
      "ucb [-0.01923553 -0.04814896 -0.05839972  0.00901931]\n",
      "performance 0.553791408572 progress 0.000151886898242\n",
      "task rewards [ 0.57823605  0.51513762  0.26174001  0.86005195]\n",
      "[chosen task]  3\n",
      "mu [-0.01664069 -0.04338986 -0.05162021  0.00411871]\n",
      "sigma [ 0.01992675  0.01880111  0.01883126  0.01275599]\n",
      "ucb [-0.01644143 -0.04320185 -0.05143189  0.00424627]\n",
      "performance 0.543019058417 progress -0.0107723501555\n",
      "task rewards [ 0.57823605  0.44500518  0.26942233  0.87941268]\n",
      "[chosen task]  3\n",
      "mu [-0.0139702  -0.03825416 -0.04452755 -0.00202163]\n",
      "sigma [ 0.01994942  0.01915543  0.01919956  0.01275309]\n",
      "ucb [-0.0137707  -0.03806261 -0.04433556 -0.0018941 ]\n",
      "performance 0.543228569077 progress 0.000209510659661\n",
      "task rewards [ 0.57823605  0.44584322  0.26942233  0.87941268]\n",
      "[chosen task]  3\n",
      "mu [-0.01147665 -0.03256082 -0.03738409 -0.00388388]\n",
      "sigma [ 0.01996642  0.01941211  0.01946983  0.01274314]\n",
      "ucb [-0.01127698 -0.0323667  -0.03718939 -0.00375645]\n",
      "performance 0.517866990564 progress -0.0253615785123\n",
      "task rewards [ 0.57823605  0.47507372  0.13874552  0.87941268]\n",
      "[chosen task]  0\n",
      "mu [-0.00926351 -0.02777455 -0.03096396 -0.01074876]\n",
      "sigma [ 0.01997855  0.01959004  0.01965933  0.01273175]\n",
      "ucb [-0.00906372 -0.02757865 -0.03076737 -0.01062144]\n",
      "performance 0.629639440368 progress 0.111772449803\n",
      "task rewards [ 0.88167275  0.80851441  0.19421415  0.63415646]\n",
      "[chosen task]  0\n",
      "mu [ 0.05256608 -0.01567612 -0.00950054 -0.01215561]\n",
      "sigma [ 0.01509721  0.01965031  0.01946317  0.01343833]\n",
      "ucb [ 0.05271705 -0.01547962 -0.00930591 -0.01202122]\n",
      "performance 0.518419369367 progress -0.111220071001\n",
      "task rewards [ 0.88033093  0.65489169  0.19067845  0.3477764 ]\n",
      "[chosen task]  0\n",
      "mu [-0.00332897 -0.01817454 -0.01918381 -0.01303982]\n",
      "sigma [ 0.01363167  0.0197148   0.01944319  0.01424418]\n",
      "ucb [-0.00319265 -0.0179774  -0.01898938 -0.01289738]\n",
      "performance 0.502738756816 progress -0.0156806125503\n",
      "task rewards [ 0.88126266  0.61281735  0.16909861  0.3477764 ]\n",
      "[chosen task]  0\n",
      "mu [-0.00755459 -0.01498143 -0.01615473 -0.01317737]\n",
      "sigma [ 0.0130647   0.01976369  0.01945231  0.01510703]\n",
      "ucb [-0.00742394 -0.0147838  -0.01596021 -0.0130263 ]\n",
      "performance 0.472947717151 progress -0.0297910396655\n",
      "task rewards [ 0.82044003  0.55891907  0.15719308  0.35523869]\n",
      "[chosen task]  1\n",
      "mu [-0.01406833 -0.01266002 -0.01445477 -0.01277825]\n",
      "sigma [ 0.01285796  0.01979926  0.01946615  0.01597745]\n",
      "ucb [-0.01393975 -0.01246203 -0.01426011 -0.01261848]\n",
      "performance 0.708825614435 progress 0.235877897284\n",
      "task rewards [ 0.82044003  0.82837744  0.29812328  0.8883617 ]\n",
      "[chosen task]  1\n",
      "mu [-0.0101318   0.11181338  0.09906775 -0.00207633]\n",
      "sigma [ 0.01355601  0.01506466  0.01557974  0.01677593]\n",
      "ucb [-0.00999624  0.11196403  0.09922355 -0.00190857]\n",
      "performance 0.733495171215 progress 0.02466955678\n",
      "task rewards [ 0.82044003  0.91679126  0.30838769  0.8883617 ]\n",
      "[chosen task]  1\n",
      "mu [-0.01210598  0.08079662  0.07101744 -0.00350001]\n",
      "sigma [ 0.01438536  0.01362239  0.01441902  0.01750745]\n",
      "ucb [-0.01196212  0.08093285  0.07116163 -0.00332493]\n",
      "performance 0.733081937743 progress -0.000413233471303\n",
      "task rewards [ 0.82044003  0.91679126  0.32135721  0.87373925]\n",
      "[chosen task]  1\n",
      "mu [-0.01398612  0.054612    0.04726899 -0.00477118]\n",
      "sigma [ 0.01527387  0.01306127  0.01398836  0.01813571]\n",
      "ucb [-0.01383338  0.05474261  0.04740887 -0.00458982]\n",
      "performance 0.67383988201 progress -0.0592420557329\n",
      "task rewards [ 0.75002867  0.91679126  0.32135721  0.70718238]\n",
      "[chosen task]  1\n",
      "mu [-0.01672042  0.02031748  0.01602187 -0.00725689]\n",
      "sigma [ 0.01615503  0.01285595  0.01385045  0.01864711]\n",
      "ucb [-0.01655887  0.02044604  0.01616038 -0.00707042]\n",
      "performance 0.686536132511 progress 0.0126962505009\n",
      "task rewards [ 0.75153182  0.91679126  0.31985737  0.75796407]\n",
      "[chosen task]  1\n",
      "mu [-0.01671556  0.01094178  0.00760093 -0.00678144]\n",
      "sigma [ 0.0169744   0.01280125  0.01383303  0.01904275]\n",
      "ucb [-0.01654582  0.01106979  0.00773926 -0.00659101]\n",
      "performance 0.608434140213 progress -0.0781019922986\n",
      "task rewards [ 0.7325248   0.74041703  0.19269475  0.76809998]\n",
      "[chosen task]  3\n",
      "mu [-0.01873021 -0.01766376 -0.0184841  -0.00891295]\n",
      "sigma [ 0.0176943   0.01279643  0.01385134  0.01933417]\n",
      "ucb [-0.01855327 -0.0175358  -0.01834558 -0.00871961]\n",
      "performance 0.563224955359 progress -0.0452091848536\n",
      "task rewards [ 0.63597785  0.73488716  0.12247889  0.75955593]\n",
      "[chosen task]  0\n",
      "mu [-0.01783344 -0.02594056 -0.02471504 -0.02601644]\n",
      "sigma [ 0.01830713  0.01353661  0.01449928  0.01502404]\n",
      "ucb [-0.01765037 -0.02580519 -0.02457005 -0.0258662 ]\n",
      "performance 0.678966030379 progress 0.11574107502\n",
      "task rewards [ 0.87062824  0.71155888  0.22625365  0.90742335]\n",
      "[chosen task]  0\n",
      "mu [ 0.04521408 -0.02783695 -0.01694773 -0.02523172]\n",
      "sigma [ 0.0148742   0.01436239  0.01505824  0.01535359]\n",
      "ucb [ 0.04536282 -0.02769333 -0.01679715 -0.02507819]\n",
      "performance 0.596177299769 progress -0.0827887306103\n",
      "task rewards [ 0.73378913  0.68753579  0.11836377  0.8450205 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00331995 -0.0343629  -0.02925086 -0.02394143]\n",
      "sigma [ 0.01360924  0.01523264  0.01572998  0.01580657]\n",
      "ucb [ 0.00345605 -0.03421057 -0.02909356 -0.02378337]\n",
      "performance 0.675337374292 progress 0.0791600745235\n",
      "task rewards [ 0.80596651  0.77271908  0.24287981  0.8797841 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.02413962 -0.03422198 -0.0260745  -0.02229133]\n",
      "sigma [ 0.01305699  0.01609325  0.01641858  0.01635184]\n",
      "ucb [ 0.02427019 -0.03406105 -0.02591032 -0.02212781]\n",
      "performance 0.678294499762 progress 0.00295712546938\n",
      "task rewards [ 0.81956778  0.7860378   0.23798437  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.01882172 -0.03462334 -0.02735288 -0.02038255]\n",
      "sigma [ 0.01283188  0.01689855  0.01707239  0.01694564]\n",
      "ucb [ 0.01895004 -0.03445436 -0.02718215 -0.02021309]\n",
      "performance 0.671937371547 progress -0.00635712821522\n",
      "task rewards [ 0.90773031  0.67386361  0.23656752  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.01186647 -0.0338173  -0.02779625 -0.01828649]\n",
      "sigma [ 0.01276522  0.01761418  0.01765668  0.01754138]\n",
      "ucb [ 0.01199412 -0.03364116 -0.02761968 -0.01811107]\n",
      "performance 0.674841589333 progress 0.00290421778622\n",
      "task rewards [ 0.90773031  0.67386361  0.24818439  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00805771 -0.03155645 -0.02645258 -0.01607582]\n",
      "sigma [ 0.01276255  0.01821945  0.01815093  0.01809826]\n",
      "ucb [ 0.00818533 -0.03137426 -0.02627107 -0.01589484]\n",
      "performance 0.679466401155 progress 0.00462481182251\n",
      "task rewards [ 0.91832543  0.68176773  0.24818439  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00529825 -0.0284262  -0.02416294 -0.01384786]\n",
      "sigma [ 0.01277202  0.01870745  0.01854797  0.01858689]\n",
      "ucb [ 0.00542597 -0.02823913 -0.02397746 -0.01366199]\n",
      "performance 0.674308292742 progress -0.00515810841287\n",
      "task rewards [ 0.88811392  0.68176773  0.25776347  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00085837 -0.02512185 -0.02196406 -0.01169922]\n",
      "sigma [ 0.01277243  0.01908299  0.01885169  0.01899142]\n",
      "ucb [ 0.00098609 -0.02493102 -0.02177554 -0.01150931]\n",
      "performance 0.719234559288 progress 0.0449262665452\n",
      "task rewards [ 0.87763637  0.68379366  0.44592016  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00954748 -0.02004313 -0.01616927 -0.00962341]\n",
      "sigma [ 0.01276181  0.01935911  0.01907347  0.01930858]\n",
      "ucb [ 0.0096751  -0.01984953 -0.01597853 -0.00943032]\n",
      "performance 0.721735007895 progress 0.00250044860743\n",
      "task rewards [ 0.92136432  0.66115889  0.43482877  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00704106 -0.0165641  -0.01350047 -0.00779573]\n",
      "sigma [ 0.01274625  0.01955325  0.01922843  0.01954473]\n",
      "ucb [ 0.00716853 -0.01636857 -0.01330819 -0.00760029]\n",
      "performance 0.719702303704 progress -0.00203270419078\n",
      "task rewards [ 0.92136432  0.66115889  0.42669795  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00401348 -0.01346778 -0.01124401 -0.00619195]\n",
      "sigma [ 0.01273223  0.01968388  0.01933223  0.01971204]\n",
      "ucb [ 0.0041408  -0.01327094 -0.01105068 -0.00599483]\n",
      "performance 0.721735007895 progress 0.00203270419078\n",
      "task rewards [ 0.92136432  0.66115889  0.43482877  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00264521 -0.0105828  -0.00891523 -0.00481444]\n",
      "sigma [ 0.01272312  0.01976804  0.01939899  0.01982503]\n",
      "ucb [ 0.00277245 -0.01038511 -0.00872124 -0.00461619]\n",
      "performance 0.722454782432 progress 0.000719774537255\n",
      "task rewards [ 0.92136432  0.66403799  0.43482877  0.86958805]\n",
      "[chosen task]  0\n",
      "mu [ 0.00142854 -0.00814648 -0.00695677 -0.00366858]\n",
      "sigma [ 0.01271904  0.01981999  0.01944026  0.01989785]\n",
      "ucb [ 0.00155573 -0.00794828 -0.00676236 -0.0034696 ]\n",
      "performance 0.672296985092 progress -0.0501577973406\n",
      "task rewards [ 0.90853916  0.66403799  0.24702274  0.86958805]\n",
      "[chosen task]  3\n",
      "mu [-0.01138983 -0.00762456 -0.00846968 -0.00279726]\n",
      "sigma [ 0.01271825  0.01985072  0.01946478  0.01994267]\n",
      "ucb [-0.01126265 -0.00742606 -0.00827503 -0.00259783]\n",
      "performance 0.704991624298 progress 0.0326946392066\n",
      "task rewards [ 0.93247162  0.71481021  0.28110032  0.89158435]\n",
      "[chosen task]  3\n",
      "mu [-0.01265586 -0.00392577 -0.00646982  0.01547931]\n",
      "sigma [ 0.01342938  0.01980429  0.01951655  0.0150957 ]\n",
      "ucb [-0.01252156 -0.00372772 -0.00627465  0.01563027]\n",
      "performance 0.665769446362 progress -0.0392221779364\n",
      "task rewards [ 0.85626306  0.63352444  0.27526402  0.89802628]\n",
      "[chosen task]  3\n",
      "mu [-0.01346722 -0.0050965  -0.00646496 -0.00309419]\n",
      "sigma [ 0.0142406   0.01980345  0.0195769   0.01363162]\n",
      "ucb [-0.01332482 -0.00489847 -0.00626919 -0.00295787]\n",
      "performance 0.666242049634 progress 0.000472603272693\n",
      "task rewards [ 0.85371226  0.59593148  0.30790111  0.90742335]\n",
      "[chosen task]  3\n",
      "mu [-0.01373721 -0.00410585 -0.00565686 -0.00228386]\n",
      "sigma [ 0.01510788  0.01981283  0.01963967  0.01306356]\n",
      "ucb [-0.01358613 -0.00390773 -0.00546046 -0.00215322]\n",
      "performance 0.65167993919 progress -0.0145621104448\n",
      "task rewards [ 0.81272887  0.5772425   0.30932503  0.90742335]\n",
      "[chosen task]  1\n",
      "mu [-0.01355709 -0.00381197 -0.00515348 -0.00554171]\n",
      "sigma [ 0.01598095  0.01982545  0.01970174  0.01285631]\n",
      "ucb [-0.01339728 -0.00361371 -0.00495646 -0.00541315]\n",
      "performance 0.723394971865 progress 0.071715032675\n",
      "task rewards [ 0.92189064  0.79488133  0.28414415  0.89266376]\n",
      "[chosen task]  1\n",
      "mu [-0.00997498  0.03380991  0.02951775 -0.00434157]\n",
      "sigma [ 0.01678039  0.01506594  0.01572264  0.01355395]\n",
      "ucb [-0.00980717  0.03396056  0.02967498 -0.00420603]\n",
      "performance 0.721799966106 progress -0.00159500575855\n",
      "task rewards [ 0.86425864  0.92650756  0.28998243  0.80645124]\n",
      "[chosen task]  1\n",
      "mu [-0.01013094  0.02115836  0.01803712 -0.00506698]\n",
      "sigma [ 0.01751159  0.01362248  0.01452956  0.01438325]\n",
      "ucb [-0.00995583  0.02129458  0.01818241 -0.00492314]\n",
      "performance 0.775053823182 progress 0.0532538570757\n",
      "task rewards [ 0.92411937  0.91679126  0.40186531  0.85743935]\n",
      "[chosen task]  1\n",
      "mu [-0.00805106  0.02881903  0.02527267 -0.00438916]\n",
      "sigma [ 0.0181389   0.01306209  0.01407557  0.015272  ]\n",
      "ucb [-0.00786967  0.02894965  0.02541342 -0.00423644]\n",
      "performance 0.799370064704 progress 0.0243162415218\n",
      "task rewards [ 0.87669533  0.91024488  0.52740125  0.8831388 ]\n",
      "[chosen task]  1\n",
      "mu [-0.00695925  0.02624216  0.02308888 -0.00430753]\n",
      "sigma [ 0.01864921  0.01285714  0.0139168   0.01615352]\n",
      "ucb [-0.00677276  0.02637073  0.02322805 -0.00414599]\n",
      "performance 0.802435861155 progress 0.00306579645138\n",
      "task rewards [ 0.90136299  0.91024488  0.52740125  0.87073433]\n",
      "[chosen task]  1\n",
      "mu [-0.00646625  0.01865082  0.01628347 -0.00466411]\n",
      "sigma [ 0.01904394  0.01280229  0.01388091  0.01697326]\n",
      "ucb [-0.00627581  0.01877884  0.01642228 -0.00449437]\n",
      "performance 0.767112117468 progress -0.0353237436873\n",
      "task rewards [ 0.85676373  0.92254893  0.49175096  0.79738485]\n",
      "[chosen task]  1\n",
      "mu [-0.00705119  0.00300045  0.00204783 -0.00595651]\n",
      "sigma [ 0.01933472  0.01279708  0.01388404  0.01769347]\n",
      "ucb [-0.00685784  0.00312842  0.00218667 -0.00577958]\n",
      "performance 0.762525768918 progress -0.00458634854934\n",
      "task rewards [ 0.79181414  0.94580413  0.49719973  0.81528507]\n",
      "[chosen task]  1\n",
      "mu [-0.00636886 -0.00230349 -0.00267554 -0.00590219]\n",
      "sigma [ 0.019539    0.01279556  0.01388821  0.01829432]\n",
      "ucb [-0.00617347 -0.00217553 -0.00253666 -0.00571925]\n",
      "performance 0.774545258744 progress 0.0120194898261\n",
      "task rewards [ 0.79181414  0.95249385  0.48380636  0.87006668]\n",
      "[chosen task]  1\n",
      "mu [-0.00508867 -0.00190684 -0.00217478 -0.00507909]\n",
      "sigma [ 0.01967602  0.01278427  0.01388267  0.01877187]\n",
      "ucb [-0.00489191 -0.001779   -0.00203595 -0.00489137]\n",
      "performance 0.73776558207 progress -0.0367796766744\n",
      "task rewards [ 0.71209109  0.88587566  0.4830289   0.87006668]\n",
      "[chosen task]  0\n",
      "mu [-0.00536332 -0.0124515  -0.01176522 -0.00568529]\n",
      "sigma [ 0.01976389  0.01276573  0.01386995  0.01913429]\n",
      "ucb [-0.00516568 -0.01232384 -0.01162652 -0.00549394]\n",
      "performance 0.731760467611 progress -0.006005114459\n",
      "task rewards [ 0.74929795  0.88677732  0.47568153  0.81528507]\n",
      "[chosen task]  0\n",
      "mu [-0.00504239 -0.01455721 -0.013661   -0.00522581]\n",
      "sigma [ 0.01506713  0.01346971  0.01430766  0.0194092 ]\n",
      "ucb [-0.00489172 -0.01442252 -0.01351792 -0.00503172]\n",
      "performance 0.791653610646 progress 0.0598931430347\n",
      "task rewards [ 0.92411937  0.95191724  0.57649972  0.71407812]\n",
      "[chosen task]  0\n",
      "mu [ 0.01761512 -0.01459735 -0.01031039 -0.00480259]\n",
      "sigma [ 0.01362348  0.01426991  0.01492519  0.01960499]\n",
      "ucb [ 0.01775136 -0.01445465 -0.01016114 -0.00460654]\n",
      "performance 0.79018401634 progress -0.0014695943058\n",
      "task rewards [ 0.93433846  0.95191724  0.57649972  0.69798066]\n",
      "[chosen task]  0\n",
      "mu [ 0.01264632 -0.01531814 -0.01174956 -0.00425656]\n",
      "sigma [ 0.01305896  0.01512252  0.01561284  0.01974015]\n",
      "ucb [ 0.01277691 -0.01516691 -0.01159343 -0.00405916]\n",
      "performance 0.795408067655 progress 0.00522405131548\n",
      "task rewards [ 0.93516442  0.95191724  0.57649972  0.7180509 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.01052643 -0.01519172 -0.01198855 -0.00371894]\n",
      "sigma [ 0.01285223  0.0159787   0.01631329  0.01983113]\n",
      "ucb [ 0.01065495 -0.01503193 -0.01182541 -0.00352063]\n",
      "performance 0.799495122932 progress 0.0040870552763\n",
      "task rewards [ 0.93600551  0.95249385  0.59143022  0.7180509 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00831544 -0.01453528 -0.01175822 -0.00319883]\n",
      "sigma [ 0.01279804  0.01679133  0.01698047  0.01989119]\n",
      "ucb [ 0.00844342 -0.01436737 -0.01158841 -0.00299992]\n",
      "performance 0.797930043103 progress -0.00156507982865\n",
      "task rewards [ 0.95081028  0.94580413  0.59143022  0.70367554]\n",
      "[chosen task]  0\n",
      "mu [ 0.004989   -0.01360897 -0.01144838 -0.00271291]\n",
      "sigma [ 0.01279457  0.01752204  0.01757937  0.01993034]\n",
      "ucb [ 0.00511694 -0.01343375 -0.01127259 -0.00251361]\n",
      "performance 0.77591158066 progress -0.0220184624433\n",
      "task rewards [ 0.95314253  0.88020325  0.59570952  0.67459103]\n",
      "[chosen task]  3\n",
      "mu [-0.00272794 -0.01298166 -0.01206807 -0.00228875]\n",
      "sigma [ 0.01279465  0.01814589  0.01808844  0.01995568]\n",
      "ucb [-0.0026     -0.0128002  -0.01188718 -0.00208919]\n",
      "performance 0.823855699369 progress 0.0479441187097\n",
      "task rewards [ 0.87411116  0.94580413  0.6372567   0.8382508 ]\n",
      "[chosen task]  3\n",
      "mu [-0.00424783 -0.00881764 -0.01013041  0.02295419]\n",
      "sigma [ 0.01353209  0.01861014  0.01854796  0.01509488]\n",
      "ucb [-0.00411251 -0.00863154 -0.00994493  0.02310513]\n",
      "performance 0.787072224049 progress -0.0367834753208\n",
      "task rewards [ 0.74022535  0.95249385  0.54814634  0.90742335]\n",
      "[chosen task]  3\n",
      "mu [-0.00552767 -0.00956806 -0.00967712  0.00224771]\n",
      "sigma [ 0.01435772  0.01899344  0.0189212   0.0136313 ]\n",
      "ucb [-0.00538409 -0.00937813 -0.00948791  0.00238402]\n",
      "performance 0.78753137532 progress 0.000459151271053\n",
      "task rewards [ 0.74022535  0.95249385  0.54814634  0.90925996]\n",
      "[chosen task]  3\n",
      "mu [-0.0063979  -0.00817146 -0.00846688  0.00113345]\n",
      "sigma [ 0.01522591  0.01928422  0.01921381  0.01306432]\n",
      "ucb [-0.00624564 -0.00797862 -0.00827474  0.0012641 ]\n",
      "performance 0.766721780091 progress -0.0208095952288\n",
      "task rewards [ 0.73272005  0.95249385  0.47241326  0.90925996]\n",
      "[chosen task]  3\n",
      "mu [-0.0069102  -0.0075115  -0.00754841 -0.00503242]\n",
      "sigma [ 0.01608893  0.01949395  0.01943661  0.01285742]\n",
      "ucb [-0.00674931 -0.00731656 -0.00735405 -0.00490385]\n",
      "performance 0.761665214519 progress -0.00505656557175\n",
      "task rewards [ 0.73793908  0.95249385  0.48040816  0.87581977]\n",
      "[chosen task]  3\n",
      "mu [-0.00705064 -0.00632528 -0.0064368  -0.00587683]\n",
      "sigma [ 0.0169027   0.01963877  0.01960205  0.01280246]\n",
      "ucb [-0.00688162 -0.00612889 -0.00624078 -0.0057488 ]\n",
      "performance 0.76034960999 progress -0.00131560452904\n",
      "task rewards [ 0.73793908  0.96221337  0.49692144  0.84432455]\n",
      "[chosen task]  1\n",
      "mu [-0.00687804 -0.00513282 -0.00535827 -0.00538196]\n",
      "sigma [ 0.01763209  0.0197348   0.01972225  0.01279763]\n",
      "ucb [-0.00670172 -0.00493547 -0.00516105 -0.00525398]\n",
      "performance 0.796064752879 progress 0.0357151428893\n",
      "task rewards [ 0.92327462  0.94580413  0.43041537  0.88476489]\n",
      "[chosen task]  1\n",
      "mu [-0.00442708  0.01582031  0.01402863 -0.00484448]\n",
      "sigma [ 0.0182053   0.01506336  0.01577659  0.01353903]\n",
      "ucb [-0.00424503  0.01597095  0.0141864  -0.00470909]\n",
      "performance 0.743867592401 progress -0.0521971604782\n",
      "task rewards [ 0.90531959  0.92698217  0.25840372  0.88476489]\n",
      "[chosen task]  3\n",
      "mu [-0.00639154 -0.00703156 -0.00696326 -0.00613281]\n",
      "sigma [ 0.01868941  0.01362339  0.01456782  0.01437437]\n",
      "ucb [-0.00620465 -0.00689533 -0.00681758 -0.00598906]\n",
      "performance 0.673616544551 progress -0.0702510478497\n",
      "task rewards [ 0.95751332  0.60722966  0.24244272  0.88728048]\n",
      "[chosen task]  0\n",
      "mu [-0.00572534 -0.00840767 -0.0067615  -0.02721563]\n",
      "sigma [ 0.01908318  0.0140964   0.01498635  0.01368921]\n",
      "ucb [-0.0055345  -0.00826671 -0.00661163 -0.02707874]\n",
      "performance 0.665181958474 progress -0.00843458607761\n",
      "task rewards [ 0.95556653  0.54995424  0.26792659  0.88728048]\n",
      "[chosen task]  0\n",
      "mu [-0.00634053 -0.0086378  -0.0070149  -0.02797241]\n",
      "sigma [ 0.01499385  0.01472897  0.01536072  0.01440425]\n",
      "ucb [-0.00619059 -0.00849051 -0.00686129 -0.02782837]\n",
      "performance 0.696145692372 progress 0.0309637338977\n",
      "task rewards [ 0.94812624  0.85873504  0.25250503  0.72521645]\n",
      "[chosen task]  0\n",
      "mu [ 0.00702463 -0.00773759 -0.00418609 -0.02791443]\n",
      "sigma [ 0.01362262  0.01547432  0.01592646  0.01516229]\n",
      "ucb [ 0.00716085 -0.00758284 -0.00402683 -0.02776281]\n",
      "performance 0.679256423314 progress -0.0168892690576\n",
      "task rewards [ 0.8680107   0.66476993  0.28713582  0.89710925]\n",
      "[chosen task]  0\n",
      "mu [ 0.00105729 -0.00811682 -0.00548108 -0.02712036]\n",
      "sigma [ 0.0130571   0.01625954  0.01655385  0.01593219]\n",
      "ucb [ 0.00118786 -0.00795422 -0.00531554 -0.02696104]\n",
      "performance 0.639326795961 progress -0.0399296273535\n",
      "task rewards [ 0.86800239  0.60790217  0.19412215  0.88728048]\n",
      "[chosen task]  2\n",
      "mu [-0.0089695  -0.00888006 -0.00777719 -0.02569901]\n",
      "sigma [ 0.0128394   0.01702121  0.01717323  0.01668071]\n",
      "ucb [-0.00884111 -0.00870984 -0.00760546 -0.02553221]\n",
      "performance 0.484949642399 progress -0.154377153561\n",
      "task rewards [ 0.65647703  0.26738038  0.30517635  0.71076481]\n",
      "[chosen task]  0\n",
      "mu [-0.01623642 -0.06517516 -0.07077844 -0.02580306]\n",
      "sigma [ 0.013491    0.01515347  0.01459661  0.01737335]\n",
      "ucb [-0.01610151 -0.06502363 -0.07063248 -0.02562933]\n",
      "performance 0.540826516672 progress 0.0558768742726\n",
      "task rewards [ 0.7749497   0.46828679  0.23965435  0.68041522]\n",
      "[chosen task]  0\n",
      "mu [ 0.00351178 -0.06440088 -0.06723308 -0.02358834]\n",
      "sigma [ 0.01322718  0.01569426  0.01506816  0.01799158]\n",
      "ucb [ 0.00364406 -0.06424394 -0.0670824  -0.02340843]\n",
      "performance 0.592905309585 progress 0.0520787929128\n",
      "task rewards [ 0.86800239  0.55885541  0.26994795  0.67481549]\n",
      "[chosen task]  0\n",
      "mu [ 0.0174235  -0.06193639 -0.06269441 -0.02108368]\n",
      "sigma [ 0.01304279  0.01625603  0.01560023  0.01851685]\n",
      "ucb [ 0.01755393 -0.06177383 -0.0625384  -0.02089852]\n",
      "performance 0.578798434985 progress -0.0141068745996\n",
      "task rewards [ 0.86800239  0.5650765   0.29557535  0.58653951]\n",
      "[chosen task]  0\n",
      "mu [ 0.01086063 -0.05928535 -0.0606641  -0.01848276]\n",
      "sigma [ 0.01291033  0.01682292  0.01616919  0.01894337]\n",
      "ucb [ 0.01098973 -0.05911712 -0.06050241 -0.01829332]\n",
      "performance 0.54117527941 progress -0.0376231555746\n",
      "task rewards [ 0.84915328  0.45482814  0.29557535  0.56514435]\n",
      "[chosen task]  0\n",
      "mu [-0.00071755 -0.05606467 -0.05874441 -0.01589148]\n",
      "sigma [ 0.01281921  0.0173754   0.01674602  0.01927438]\n",
      "ucb [-0.00058936 -0.05589091 -0.05857695 -0.01569874]\n",
      "performance 0.561512153003 progress 0.0203368735921\n",
      "task rewards [ 0.88454512  0.46256837  0.28888199  0.61005312]\n",
      "[chosen task]  0\n",
      "mu [ 0.00367648 -0.05052025 -0.05232083 -0.01334027]\n",
      "sigma [ 0.01276298  0.01789276  0.01730046  0.01951997]\n",
      "ucb [ 0.00380411 -0.05034132 -0.05214783 -0.01314507]\n",
      "performance 0.552968686675 progress -0.00854346632713\n",
      "task rewards [ 0.81977263  0.46354578  0.23832986  0.69022647]\n",
      "[chosen task]  0\n",
      "mu [ 0.00040525 -0.04522303 -0.04719127 -0.01100012]\n",
      "sigma [ 0.01273413  0.01835661  0.01780579  0.01969423]\n",
      "ucb [ 0.00053259 -0.04503946 -0.04701321 -0.01080317]\n",
      "performance 0.577756877509 progress 0.0247881908332\n",
      "task rewards [ 0.87097204  0.46354578  0.25410756  0.72240212]\n",
      "[chosen task]  0\n",
      "mu [ 0.00555783 -0.03868661 -0.03966042 -0.00885781]\n",
      "sigma [ 0.01272365  0.0187539   0.01824278  0.01981251]\n",
      "ucb [ 0.00568507 -0.03849907 -0.039478   -0.00865968]\n",
      "performance 0.581383104986 progress 0.00362622747738\n",
      "task rewards [ 0.87150038  0.46791792  0.263712    0.72240212]\n",
      "[chosen task]  0\n",
      "mu [ 0.00490836 -0.03289024 -0.03368556 -0.00701137]\n",
      "sigma [ 0.01272266  0.01907861  0.01860164  0.01988935]\n",
      "ucb [ 0.00503559 -0.03269945 -0.03349954 -0.00681248]\n",
      "performance 0.564583537599 progress -0.0167995673868\n",
      "task rewards [ 0.88524625  0.41459617  0.2360896   0.72240212]\n",
      "[chosen task]  0\n",
      "mu [-0.0005437  -0.02797978 -0.02928364 -0.00546708]\n",
      "sigma [ 0.0127244   0.01933177  0.0188818   0.01993714]\n",
      "ucb [-0.00041646 -0.02778646 -0.02909482 -0.0052677 ]\n",
      "performance 0.581498829173 progress 0.0169152915743\n",
      "task rewards [ 0.87984333  0.43113291  0.2360896   0.77892947]\n",
      "[chosen task]  0\n",
      "mu [ 0.00287453 -0.0223851  -0.02298524 -0.00414884]\n",
      "sigma [ 0.01272519  0.01952009  0.01909     0.01996561]\n",
      "ucb [ 0.00300179 -0.0221899  -0.02279434 -0.00394919]\n",
      "performance 0.588419270002 progress 0.00692044082886\n",
      "task rewards [ 0.8897616   0.41489912  0.27008689  0.77892947]\n",
      "[chosen task]  0\n",
      "mu [ 0.00352452 -0.01771547 -0.01802425 -0.00309485]\n",
      "sigma [ 0.01272408  0.01965379  0.01923749  0.01998185]\n",
      "ucb [ 0.00365176 -0.01751893 -0.01783187 -0.00289503]\n",
      "performance 0.59942298605 progress 0.0110037160472\n",
      "task rewards [ 0.8897616   0.41489912  0.27008689  0.82294434]\n",
      "[chosen task]  0\n",
      "mu [ 0.00507205 -0.01355984 -0.01348034 -0.00225841]\n",
      "sigma [ 0.01272172  0.01974446  0.01933722  0.01999075]\n",
      "ucb [ 0.00519927 -0.0133624  -0.01328697 -0.00205851]\n",
      "performance 0.646425361941 progress 0.0470023758917\n",
      "task rewards [ 0.93491168  0.59022979  0.27008689  0.79047309]\n",
      "[chosen task]  0\n",
      "mu [ 0.0148813  -0.00900421 -0.00741468 -0.00157152]\n",
      "sigma [ 0.01271924  0.01980322  0.01940172  0.01999541]\n",
      "ucb [ 0.01500849 -0.00880618 -0.00722066 -0.00137157]\n",
      "performance 0.667739484246 progress 0.0213141223046\n",
      "task rewards [ 0.93491168  0.68059294  0.27008689  0.78536643]\n",
      "[chosen task]  0\n",
      "mu [ 0.01690125 -0.0060405  -0.00405146 -0.00108005]\n",
      "sigma [ 0.01271742  0.01983966  0.01944165  0.01999776]\n",
      "ucb [ 0.01702843 -0.00584211 -0.00385704 -0.00088007]\n",
      "performance 0.674420294616 progress 0.00668081037058\n",
      "task rewards [ 0.93575312  0.69405994  0.2825017   0.78536643]\n",
      "[chosen task]  0\n",
      "mu [ 0.01471259 -0.00415571 -0.00237646 -0.00073521]\n",
      "sigma [ 0.01271649  0.01986129  0.01946537  0.0199989 ]\n",
      "ucb [ 0.01483976 -0.0039571  -0.00218181 -0.00053522]\n",
      "performance 0.674420294616 progress 0.0\n",
      "task rewards [ 0.93575312  0.69405994  0.2825017   0.78536643]\n",
      "[chosen task]  0\n",
      "mu [ 0.01086868 -0.00295923 -0.0016408  -0.00049695]\n",
      "sigma [ 0.01271624  0.01987359  0.0194789   0.01999942]\n",
      "ucb [ 0.01099584 -0.0027605  -0.00144601 -0.00029695]\n",
      "performance 0.674209935907 progress -0.000210358709245\n",
      "task rewards [ 0.93491168  0.69405994  0.2825017   0.78536643]\n",
      "[chosen task]  0\n",
      "mu [ 0.00731341 -0.0021327  -0.00125252 -0.00033235]\n",
      "sigma [ 0.0127163   0.01988029  0.01948632  0.01999966]\n",
      "ucb [ 0.00744057 -0.00193389 -0.00105766 -0.00013235]\n",
      "performance 0.674151825947 progress -5.81099602766e-05\n",
      "task rewards [ 0.93491168  0.68059294  0.31562733  0.76547535]\n",
      "[chosen task]  0\n",
      "mu [ 0.00428444 -0.00157102 -0.00107032 -0.00022092]\n",
      "sigma [ 0.0127164   0.0198838   0.01949022  0.01999976]\n",
      "ucb [  4.41160126e-03  -1.37218366e-03  -8.75415394e-04  -2.09257766e-05]\n",
      "performance 0.672080482692 progress -0.00207134325516\n",
      "task rewards [ 0.93532085  0.68835082  0.29917491  0.76547535]\n",
      "[chosen task]  0\n",
      "mu [ 0.00136053 -0.00125672 -0.00113231 -0.00014937]\n",
      "sigma [ 0.01271639  0.01988555  0.01949218  0.0199998 ]\n",
      "ucb [  1.48769827e-03  -1.05786797e-03  -9.37385950e-04   5.06309410e-05]\n",
      "performance 0.633918469282 progress -0.03816201341\n",
      "task rewards [ 0.86153632  0.51650941  0.35079837  0.80682978]\n",
      "[chosen task]  3\n",
      "mu [-0.00938752 -0.00211572 -0.00346459 -0.00014416]\n",
      "sigma [ 0.01271628  0.0198864   0.01949313  0.01999982]\n",
      "ucb [ -9.26035644e-03  -1.91685396e-03  -3.26965565e-03   5.58431469e-05]\n",
      "performance 0.64912077758 progress 0.0152023082984\n",
      "task rewards [ 0.84905484  0.53614009  0.32385208  0.88743609]\n",
      "[chosen task]  3\n",
      "mu [-0.0111988  -0.00106935 -0.00322798  0.00748117]\n",
      "sigma [ 0.01342577  0.01982231  0.01953114  0.01509897]\n",
      "ucb [-0.01106454 -0.00087113 -0.00303267  0.00763216]\n",
      "performance 0.643261262674 progress -0.00585951490633\n",
      "task rewards [ 0.86153632  0.53614009  0.32385208  0.85151656]\n",
      "[chosen task]  3\n",
      "mu [-0.01247148 -0.00159571 -0.00356155  0.00272919]\n",
      "sigma [ 0.01423498  0.01981238  0.01958401  0.01363168]\n",
      "ucb [-0.01232913 -0.00139759 -0.00336571  0.00286551]\n",
      "performance 0.577046598246 progress -0.0662146644281\n",
      "task rewards [ 0.49184392  0.56111608  0.32403414  0.93119225]\n",
      "[chosen task]  1\n",
      "mu [-0.01320697 -0.00394555 -0.00454318 -0.01667247]\n",
      "sigma [ 0.01510065  0.01981707  0.01964284  0.01306496]\n",
      "ucb [-0.01305597 -0.00374738 -0.00434675 -0.01654182]\n",
      "performance 0.74388011306 progress 0.166833514815\n",
      "task rewards [ 0.95270108  0.92665575  0.20613298  0.89003064]\n",
      "[chosen task]  1\n",
      "mu [-0.00748222  0.07990431  0.07238918 -0.01377297]\n",
      "sigma [ 0.01594972  0.01506306  0.01568715  0.01367662]\n",
      "ucb [-0.00732272  0.08005494  0.07254606 -0.0136362 ]\n",
      "performance 0.702319575249 progress -0.0415605378111\n",
      "task rewards [ 0.8640897   0.94327624  0.33286612  0.66904623]\n",
      "[chosen task]  1\n",
      "mu [-0.01041978  0.03635822  0.03251082 -0.01612395]\n",
      "sigma [ 0.01676583  0.01362141  0.01450412  0.01444681]\n",
      "ucb [-0.01025212  0.03649444  0.03265586 -0.01597948]\n",
      "performance 0.639935543613 progress -0.0623840316359\n",
      "task rewards [ 0.8640897   0.92852933  0.2111006   0.55602254]\n",
      "[chosen task]  1\n",
      "mu [-0.0125509   0.00574453  0.00448417 -0.01807647]\n",
      "sigma [ 0.01750275  0.01306194  0.01405713  0.01529964]\n",
      "ucb [-0.01237587  0.00587515  0.00462474 -0.01792348]\n",
      "performance 0.696118398278 progress 0.056182854665\n",
      "task rewards [ 0.93518454  0.92852933  0.42456642  0.49619331]\n",
      "[chosen task]  1\n",
      "mu [-0.01027504  0.01430985  0.01251734 -0.01649947]\n",
      "sigma [ 0.01813304  0.01285742  0.0139038   0.01616289]\n",
      "ucb [-0.01009371  0.01443842  0.01265638 -0.01633784]\n",
      "performance 0.742525458341 progress 0.0464070600626\n",
      "task rewards [ 0.93518454  0.94327624  0.51020467  0.58143638]\n",
      "[chosen task]  1\n",
      "mu [-0.0082067   0.01898789  0.01697264 -0.01475544]\n",
      "sigma [ 0.01864502  0.01280265  0.01387205  0.01697589]\n",
      "ucb [-0.00802025  0.01911591  0.01711136 -0.01458568]\n",
      "performance 0.748004786446 progress 0.00547932810496\n",
      "task rewards [ 0.93409316  0.93568734  0.51020467  0.61203397]\n",
      "[chosen task]  1\n",
      "mu [-0.00739825  0.01330704  0.01187714 -0.01392922]\n",
      "sigma [ 0.0190407   0.01279733  0.0138782   0.01769552]\n",
      "ucb [-0.00720785  0.01343502  0.01201593 -0.01375227]\n",
      "performance 0.749593523532 progress 0.00158873708634\n",
      "task rewards [ 0.87923958  0.93568734  0.58142671  0.60202046]\n",
      "[chosen task]  1\n",
      "mu [-0.00657386  0.00796063  0.0070744  -0.01289631]\n",
      "sigma [ 0.01933212  0.01279567  0.01388448  0.01829808]\n",
      "ucb [-0.00638054  0.00808859  0.00721324 -0.01271333]\n",
      "performance 0.728874458093 progress -0.0207190654391\n",
      "task rewards [ 0.93409316  0.93568734  0.44369687  0.60202046]\n",
      "[chosen task]  1\n",
      "mu [-0.00635987 -0.0013966  -0.00143937 -0.0123022 ]\n",
      "sigma [ 0.01953693  0.01278427  0.01388033  0.01877737]\n",
      "ucb [-0.0061645  -0.00126876 -0.00130057 -0.01211443]\n",
      "performance 0.746680097935 progress 0.0178056398421\n",
      "task rewards [ 0.93409316  0.93568734  0.37732481  0.73961508]\n",
      "[chosen task]  1\n",
      "mu [-0.00480747  0.00074332  0.00060641 -0.01021201]\n",
      "sigma [ 0.01967446  0.01276568  0.01386852  0.01914063]\n",
      "ucb [-0.00461073  0.00087097  0.0007451  -0.0100206 ]\n",
      "performance 0.768351158133 progress 0.0216710601978\n",
      "task rewards [ 0.94341788  0.95549642  0.45875251  0.71573781]\n",
      "[chosen task]  1\n",
      "mu [-0.00327047  0.00421047  0.00385153 -0.00804277]\n",
      "sigma [ 0.01976281  0.01274676  0.01385526  0.01940348]\n",
      "ucb [-0.00307285  0.00433794  0.00399008 -0.00784873]\n",
      "performance 0.739921819098 progress -0.0284293390348\n",
      "task rewards [ 0.94341788  0.95549642  0.45875251  0.60202046]\n",
      "[chosen task]  0\n",
      "mu [-0.00342198 -0.0042909  -0.0039336  -0.00753918]\n",
      "sigma [ 0.01981717  0.01273247  0.01384506  0.01958536]\n",
      "ucb [-0.00322381 -0.00416357 -0.00379515 -0.00734332]\n",
      "performance 0.76160930982 progress 0.0216874907223\n",
      "task rewards [ 0.96658666  0.93204473  0.45875251  0.68905334]\n",
      "[chosen task]  0\n",
      "mu [ 0.00954333 -0.00480289 -0.00252376 -0.00631729]\n",
      "sigma [ 0.01507104  0.01343261  0.01427893  0.01971701]\n",
      "ucb [ 0.00969404 -0.00466856 -0.00238098 -0.00612012]\n",
      "performance 0.769851764171 progress 0.00824245435014\n",
      "task rewards [ 0.96698043  0.94026059  0.45875251  0.71341353]\n",
      "[chosen task]  0\n",
      "mu [ 0.00927589 -0.00535613 -0.00314169 -0.00515464]\n",
      "sigma [ 0.01362341  0.01423463  0.01489783  0.01980608]\n",
      "ucb [ 0.00941212 -0.00521378 -0.00299271 -0.00495658]\n",
      "performance 0.79109166826 progress 0.0212399040896\n",
      "task rewards [ 0.96658666  0.95549642  0.5033666   0.73891699]\n",
      "[chosen task]  0\n",
      "mu [ 0.0124495  -0.00529518 -0.00267253 -0.00414932]\n",
      "sigma [ 0.01305982  0.01509285  0.01558991  0.01986599]\n",
      "ucb [ 0.0125801  -0.00514425 -0.00251664 -0.00395066]\n",
      "performance 0.76380433806 progress -0.0272873302002\n",
      "task rewards [ 0.95036825  0.9541056   0.36842841  0.78231509]\n",
      "[chosen task]  0\n",
      "mu [ 0.00212403 -0.00610972 -0.00502379 -0.00329697]\n",
      "sigma [ 0.012854    0.01595619  0.01629598  0.01990657]\n",
      "ucb [ 0.00225257 -0.00595016 -0.00486083 -0.00309791]\n",
      "performance 0.793571838891 progress 0.0297675008305\n",
      "task rewards [ 0.96658666  0.9541056   0.46189571  0.79169938]\n",
      "[chosen task]  0\n",
      "mu [ 0.00779901 -0.00513054 -0.00332518 -0.00256608]\n",
      "sigma [ 0.01279987  0.01677571  0.01696852  0.01993455]\n",
      "ucb [ 0.00792701 -0.00496278 -0.00315549 -0.00236674]\n",
      "performance 0.793571838891 progress 0.0\n",
      "task rewards [ 0.96658666  0.9541056   0.46189571  0.79169938]\n",
      "[chosen task]  0\n",
      "mu [ 0.00531667 -0.00489589 -0.00352278 -0.00199092]\n",
      "sigma [ 0.01279589  0.01751208  0.01757176  0.01995423]\n",
      "ucb [ 0.00544463 -0.00472077 -0.00334707 -0.00179138]\n",
      "performance 0.716078803966 progress -0.0774930349241\n",
      "task rewards [ 0.96658666  0.9541056   0.25843098  0.68519197]\n",
      "[chosen task]  3\n",
      "mu [-0.01553737 -0.00689453 -0.0085061  -0.00162418]\n",
      "sigma [ 0.01279533  0.01814     0.01808396  0.01996831]\n",
      "ucb [-0.01540942 -0.00671313 -0.00832526 -0.0014245 ]\n",
      "performance 0.750594467663 progress 0.0345156636971\n",
      "task rewards [ 0.857689    0.9541056   0.25843098  0.93215228]\n",
      "[chosen task]  3\n",
      "mu [-0.01765038 -0.00458853 -0.0078977   0.01661147]\n",
      "sigma [ 0.01353254  0.01860712  0.01854561  0.01509548]\n",
      "ucb [-0.01751506 -0.00440246 -0.00771224  0.01676243]\n",
      "performance 0.676593264466 progress -0.0740012031976\n",
      "task rewards [ 0.63402115  0.944307    0.19589262  0.93215228]\n",
      "[chosen task]  1\n",
      "mu [-0.01915752 -0.00761561 -0.00888181 -0.01449037]\n",
      "sigma [ 0.01435795  0.01899199  0.01892005  0.01363134]\n",
      "ucb [-0.01901394 -0.00742569 -0.00869261 -0.01435405]\n",
      "performance 0.68834276085 progress 0.0117494963843\n",
      "task rewards [ 0.63402115  0.94580413  0.24139348  0.93215228]\n",
      "[chosen task]  1\n",
      "mu [ -1.92376146e-02   2.10619375e-03  -6.82322927e-05  -1.42707369e-02]\n",
      "sigma [ 0.01520645  0.01497475  0.01558678  0.01410003]\n",
      "ucb [ -1.90855501e-02   2.25594122e-03   8.76355122e-05  -1.41297367e-02]\n",
      "performance 0.695105492117 progress 0.00676273126707\n",
      "task rewards [ 0.63402115  0.95549642  0.25875211  0.93215228]\n",
      "[chosen task]  1\n",
      "mu [-0.01906521  0.00409256  0.00175417 -0.0141192 ]\n",
      "sigma [ 0.01605636  0.01361664  0.01447698  0.0147453 ]\n",
      "ucb [-0.01890465  0.00422872  0.00189894 -0.01397175]\n",
      "performance 0.66318099672 progress -0.0319244953975\n",
      "task rewards [ 0.49960622  0.96221337  0.25875211  0.93215228]\n",
      "[chosen task]  1\n",
      "mu [-0.0193522  -0.00562391 -0.00709613 -0.0145531 ]\n",
      "sigma [ 0.01685864  0.01305462  0.01403142  0.01549712]\n",
      "ucb [-0.01918362 -0.00549336 -0.00695582 -0.01439813]\n",
      "performance 0.708530381673 progress 0.0453493849534\n",
      "task rewards [ 0.49665782  0.96221337  0.46143409  0.91381624]\n",
      "[chosen task]  1\n",
      "mu [-0.01680685  0.00705333  0.00469991 -0.01276767]\n",
      "sigma [ 0.01757702  0.01283791  0.01387182  0.01628484]\n",
      "ucb [-0.01663107  0.00718171  0.00483863 -0.01260482]\n",
      "performance 0.710080927431 progress 0.00155054575785\n",
      "task rewards [ 0.75094524  0.77452448  0.40103774  0.91381624]\n",
      "[chosen task]  1\n",
      "mu [-0.01534859  0.00623471  0.00412505 -0.0119844 ]\n",
      "sigma [ 0.01818847  0.01277874  0.01384028  0.01704573]\n",
      "ucb [-0.0151667   0.0063625   0.00426345 -0.01181394]\n",
      "performance 0.711512264267 progress 0.00143133683559\n",
      "task rewards [ 0.79178835  0.94504196  0.22416706  0.88505169]\n",
      "[chosen task]  1\n",
      "mu [-0.01366087  0.00526611  0.00343736 -0.01102897]\n",
      "sigma [ 0.01868386  0.01277748  0.01385327  0.01773224]\n",
      "ucb [-0.01347403  0.00539388  0.00357589 -0.01085165]\n",
      "performance 0.666890962561 progress -0.0446213017056\n",
      "task rewards [ 0.79178835  0.96171682  0.27501143  0.63904725]\n",
      "[chosen task]  1\n",
      "mu [-0.01329004 -0.00684669 -0.00750029 -0.01134498]\n",
      "sigma [ 0.01906636  0.01278351  0.01386871  0.0183155 ]\n",
      "ucb [-0.01309937 -0.00671886 -0.00736161 -0.01116182]\n",
      "performance 0.663848805602 progress -0.00304215695888\n",
      "task rewards [ 0.79178835  0.96171682  0.27501143  0.62687862]\n",
      "[chosen task]  1\n",
      "mu [-0.01135676 -0.00698885 -0.00742061 -0.01006101]\n",
      "sigma [ 0.01934816  0.01277892  0.01387226  0.01878461]\n",
      "ucb [-0.01116327 -0.00686106 -0.00728188 -0.00987316]\n",
      "performance 0.663915493315 progress 6.6687713362e-05\n",
      "task rewards [ 0.78584831  0.96171682  0.28121822  0.62687862]\n",
      "[chosen task]  1\n",
      "mu [-0.00937721 -0.00601475 -0.00632897 -0.00862106]\n",
      "sigma [ 0.01954645  0.01276427  0.01386509  0.01914309]\n",
      "ucb [-0.00918174 -0.0058871  -0.00619032 -0.00842963]\n",
      "performance 0.6293271528 progress -0.0345883405156\n",
      "task rewards [ 0.67127888  0.96171682  0.25743429  0.62687862]\n",
      "[chosen task]  3\n",
      "mu [-0.00859611 -0.01317348 -0.01274313 -0.00826808]\n",
      "sigma [ 0.01967987  0.01274661  0.01385374  0.01940405]\n",
      "ucb [-0.00839931 -0.01304601 -0.01260459 -0.00807403]\n",
      "performance 0.731243134254 progress 0.101915981454\n",
      "task rewards [ 0.78586277  0.9541056   0.25743429  0.92756987]\n",
      "[chosen task]  3\n",
      "mu [-0.00746768 -0.01151083 -0.01456226  0.04630006]\n",
      "sigma [ 0.01977708  0.01344582  0.01445116  0.01503142]\n",
      "ucb [-0.00726991 -0.01137637 -0.01441775  0.04645037]\n",
      "performance 0.683705214533 progress -0.0475379197209\n",
      "task rewards [ 0.59432027  0.95549642  0.25743429  0.92756987]\n",
      "[chosen task]  3\n",
      "mu [-0.00606063 -0.01320684 -0.01384401  0.01437314]\n",
      "sigma [ 0.01984274  0.01424457  0.01513459  0.01362289]\n",
      "ucb [-0.0058622  -0.0130644  -0.01369266  0.01450937]\n",
      "performance 0.708197355913 progress 0.0244921413797\n",
      "task rewards [ 0.64863179  0.95549642  0.29650893  0.93215228]\n",
      "[chosen task]  3\n",
      "mu [-0.0049687  -0.01274545 -0.01337668  0.01619278]\n",
      "sigma [ 0.01988746  0.01509874  0.01586546  0.01305643]\n",
      "ucb [-0.00476983 -0.01259446 -0.01321803  0.01632334]\n",
      "performance 0.726373650992 progress 0.0181762950796\n",
      "task rewards [ 0.74953533  0.95549642  0.26831057  0.93215228]\n",
      "[chosen task]  3\n",
      "mu [-0.00403237 -0.01208072 -0.01258055  0.01540386]\n",
      "sigma [ 0.01991864  0.01595848  0.01660145  0.01284394]\n",
      "ucb [-0.00383318 -0.01192113 -0.01241453  0.0155323 ]\n",
      "performance 0.655154497739 progress -0.071219153253\n",
      "task rewards [ 0.53647182  0.95549642  0.19649746  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [-0.0033056  -0.01347855 -0.01229651 -0.00712694]\n",
      "sigma [ 0.01994104  0.01677552  0.01730164  0.01278766]\n",
      "ucb [-0.00310619 -0.01331079 -0.01212349 -0.00699906]\n",
      "performance 0.787532301813 progress 0.132377804073\n",
      "task rewards [ 0.96658666  0.95532361  0.29606666  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.06436652 -0.00653313  0.00439869 -0.00997087]\n",
      "sigma [ 0.01509142  0.0174818   0.01767114  0.01352807]\n",
      "ucb [ 0.06451743 -0.00635831  0.00457541 -0.00983559]\n",
      "performance 0.767535069207 progress -0.0199972326053\n",
      "task rewards [ 0.9291652   0.95549642  0.25332637  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.03423655 -0.00829422 -0.00158751 -0.01239251]\n",
      "sigma [ 0.01363051  0.01810301  0.01811583  0.01437829]\n",
      "ucb [ 0.03437285 -0.00811319 -0.00140636 -0.01224873]\n",
      "performance 0.77689043459 progress 0.00935536538308\n",
      "task rewards [ 0.96658666  0.95549642  0.25332637  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.02496917 -0.00799985 -0.00260672 -0.0141013 ]\n",
      "sigma [ 0.01306444  0.0186135   0.01850666  0.0152762 ]\n",
      "ucb [ 0.02509981 -0.00781372 -0.00242166 -0.01394854]\n",
      "performance 0.796234391226 progress 0.019343956636\n",
      "task rewards [ 0.96658666  0.9541056   0.33209302  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.02054314 -0.00713398 -0.00242383 -0.01507597]\n",
      "sigma [ 0.0128577   0.01901169  0.01881937  0.01616277]\n",
      "ucb [ 0.02067172 -0.00694386 -0.00223564 -0.01491434]\n",
      "performance 0.827095840231 progress 0.0308614490047\n",
      "task rewards [ 0.96658666  0.9541056   0.45553881  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.01980299 -0.00582144 -0.00132521 -0.01533639]\n",
      "sigma [ 0.01280259  0.01930754  0.01905363  0.01698866]\n",
      "ucb [ 0.01993101 -0.00562836 -0.00113467 -0.0151665 ]\n",
      "performance 0.789470389919 progress -0.0376254503126\n",
      "task rewards [ 0.86800767  0.9541056   0.403616    0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.00284295 -0.0066666  -0.00466814 -0.01504409]\n",
      "sigma [ 0.01279757  0.01951733  0.01921903  0.01771841]\n",
      "ucb [ 0.00297093 -0.00647143 -0.00447595 -0.01486691]\n",
      "performance 0.815843975459 progress 0.0263735855405\n",
      "task rewards [ 0.93777415  0.9541056   0.43934386  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.00467314 -0.00518402 -0.00310125 -0.01415622]\n",
      "sigma [ 0.0127962   0.01965954  0.0193294   0.01833208]\n",
      "ucb [ 0.00480111 -0.00498742 -0.00290795 -0.0139729 ]\n",
      "performance 0.820424697094 progress 0.00458072163505\n",
      "task rewards [ 0.93990209  0.9541056   0.45553881  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.00183942 -0.00444013 -0.0029316  -0.01291348]\n",
      "sigma [ 0.01278486  0.01975186  0.01939918  0.01882425]\n",
      "ucb [ 0.00196727 -0.00424261 -0.00273761 -0.01272524]\n",
      "performance 0.827243791322 progress 0.0068190942276\n",
      "task rewards [ 0.96881564  0.95249301  0.45553881  0.9321277 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00079488 -0.00361359 -0.00243303 -0.0114237 ]\n",
      "sigma [ 0.01276615  0.01980937  0.01944116  0.01920122]\n",
      "ucb [ 0.00092254 -0.0034155  -0.00223862 -0.01123168]\n",
      "performance 0.826686544987 progress -0.000557246334497\n",
      "task rewards [ 0.96658666  0.95249301  0.45553881  0.9321277 ]\n",
      "[chosen task]  0\n",
      "mu [-0.00110795 -0.00304026 -0.00230077 -0.00982894]\n",
      "sigma [ 0.01274704  0.01984382  0.01946535  0.01947724]\n",
      "ucb [-0.00098048 -0.00284182 -0.00210612 -0.00963417]\n",
      "performance 0.872116017956 progress 0.045429472969\n",
      "task rewards [ 0.96658666  0.95249301  0.6372567   0.9321277 ]\n",
      "[chosen task]  0\n",
      "mu [ 0.00887904 -0.00112007  0.00084414 -0.00817684]\n",
      "sigma [ 0.01273259  0.01986373  0.01947883  0.01967057]\n",
      "ucb [ 0.00900637 -0.00092143  0.00103893 -0.00798013]\n",
      "performance 0.83686428059 progress -0.0352517373667\n",
      "task rewards [ 0.96698043  0.95249301  0.49585599  0.9321277 ]\n",
      "[chosen task]  2\n",
      "mu [-0.00147675 -0.00186488 -0.00148766 -0.00671084]\n",
      "sigma [ 0.01272429  0.01987486  0.01948618  0.01980017]\n",
      "ucb [-0.00134951 -0.00166613 -0.0012928  -0.00651284]\n",
      "performance 0.549819517807 progress -0.287044762783\n",
      "task rewards [ 0.59572398  0.27498305  0.55235614  0.77621491]\n",
      "[chosen task]  3\n",
      "mu [-0.013667   -0.13157245 -0.13931467 -0.01233844]\n",
      "sigma [ 0.01340119  0.01584894  0.01498971  0.01987166]\n",
      "ucb [-0.01353299 -0.13141396 -0.13916477 -0.01213972]\n",
      "performance 0.57824522939 progress 0.0284257115836\n",
      "task rewards [ 0.57823605  0.47739715  0.35259797  0.90474976]\n",
      "[chosen task]  3\n",
      "mu [-0.01476199 -0.1255308  -0.13488124  0.0091388 ]\n",
      "sigma [ 0.0142069   0.0160389   0.01528923  0.01508866]\n",
      "ucb [-0.01461992 -0.12537041 -0.13472835  0.00928969]\n",
      "performance 0.58490774451 progress 0.00666251511952\n",
      "task rewards [ 0.57823605  0.47763017  0.35487539  0.92888937]\n",
      "[chosen task]  3\n",
      "mu [-0.01529515 -0.11940606 -0.12851054  0.00905561]\n",
      "sigma [ 0.01507148  0.01639168  0.01574136  0.01363062]\n",
      "ucb [-0.01514444 -0.11924214 -0.12835313  0.00919191]\n",
      "performance 0.585005456539 progress 9.77120292337e-05\n",
      "task rewards [ 0.57823605  0.47876573  0.35413068  0.92888937]\n",
      "[chosen task]  3\n",
      "mu [-0.01531851 -0.11155829 -0.12008203  0.00689745]\n",
      "sigma [ 0.01594462  0.0168431   0.01629838  0.01306219]\n",
      "ucb [-0.01515906 -0.11138986 -0.11991905  0.00702807]\n",
      "performance 0.570219855282 progress -0.014785601257\n",
      "task rewards [ 0.57823605  0.47876573  0.32785696  0.89602068]\n",
      "[chosen task]  3\n",
      "mu [-0.01490214 -0.10259411 -0.11013777  0.00135218]\n",
      "sigma [ 0.01677748  0.01734267  0.01690667  0.01285422]\n",
      "ucb [-0.01473436 -0.10242069 -0.1099687   0.00148072]\n",
      "performance 0.578988512122 progress 0.00876865684006\n",
      "task rewards [ 0.57823605  0.48758645  0.35411088  0.89602068]\n",
      "[chosen task]  3\n",
      "mu [-0.01408827 -0.09181298 -0.09877905  0.00257143]\n",
      "sigma [ 0.01753002  0.01784472  0.01751463  0.01279954]\n",
      "ucb [-0.01391297 -0.09163454 -0.0986039   0.00269942]\n",
      "performance 0.590508105023 progress 0.0115195929002\n",
      "task rewards [ 0.57823605  0.50528263  0.3805142   0.89799955]\n",
      "[chosen task]  3\n",
      "mu [-0.01297949 -0.08044063 -0.08679161  0.00421688]\n",
      "sigma [ 0.01817556  0.01831236  0.01807969  0.01279574]\n",
      "ucb [-0.01279773 -0.08025751 -0.08661082  0.00434484]\n",
      "performance 0.592860502688 progress 0.0023523976654\n",
      "task rewards [ 0.57823605  0.4873195   0.37556572  0.93032074]\n",
      "[chosen task]  3\n",
      "mu [-0.01168085 -0.06932291 -0.07484112  0.00336447]\n",
      "sigma [ 0.01870221  0.01872054  0.01857266  0.01279549]\n",
      "ucb [-0.01149382 -0.0691357  -0.0746554   0.00349243]\n",
      "performance 0.591449693403 progress -0.00141080928459\n",
      "task rewards [ 0.57619365  0.4873195   0.37196489  0.93032074]\n",
      "[chosen task]  3\n",
      "mu [-0.01027244 -0.0586699  -0.06330096  0.00173416]\n",
      "sigma [ 0.01911144  0.01905665  0.01897869  0.01278479]\n",
      "ucb [-0.01008132 -0.05847933 -0.06311118  0.00186201]\n",
      "performance 0.582599481505 progress -0.00885021189843\n",
      "task rewards [ 0.57619365  0.4873195   0.33656404  0.93032074]\n",
      "[chosen task]  3\n",
      "mu [-0.00883824 -0.04890655 -0.05257391 -0.00135992]\n",
      "sigma [ 0.01941467  0.01931894  0.01929567  0.01276625]\n",
      "ucb [-0.00864409 -0.04871336 -0.05238096 -0.00123225]\n",
      "performance 0.608653914905 progress 0.0260544334002\n",
      "task rewards [ 0.57619365  0.56230898  0.36579229  0.93032074]\n",
      "[chosen task]  3\n",
      "mu [-0.00739287 -0.0389616  -0.04239248  0.00455391]\n",
      "sigma [ 0.01962913  0.01951351  0.01953087  0.01274705]\n",
      "ucb [-0.00719658 -0.03876647 -0.04219717  0.00468139]\n",
      "performance 0.587461236321 progress -0.0211926785841\n",
      "task rewards [ 0.57619365  0.47763017  0.36570039  0.93032074]\n",
      "[chosen task]  3\n",
      "mu [-0.00609911 -0.03163666 -0.03399954 -0.00161796]\n",
      "sigma [ 0.01977402  0.019651    0.01969706  0.01273247]\n",
      "ucb [-0.00590137 -0.03144015 -0.03380256 -0.00149064]\n",
      "performance 0.605449247752 progress 0.0179880114313\n",
      "task rewards [ 0.57619365  0.55101359  0.36570039  0.92888937]\n",
      "[chosen task]  3\n",
      "mu [-0.00488099 -0.02418077 -0.0263261   0.00254516]\n",
      "sigma [ 0.01986759  0.01974371  0.01980906  0.01272411]\n",
      "ucb [-0.00468231 -0.02398333 -0.02612801  0.0026724 ]\n",
      "performance 0.605629859353 progress 0.000180611601053\n",
      "task rewards [ 0.57619365  0.6273966   0.3350439   0.88388529]\n",
      "[chosen task]  3\n",
      "mu [-0.0038369  -0.01847092 -0.02012518  0.0019572 ]\n",
      "sigma [ 0.01992539  0.01980342  0.01988114  0.01272076]\n",
      "ucb [-0.00363764 -0.01827288 -0.01992637  0.00208441]\n",
      "performance 0.62906404229 progress 0.0234341829365\n",
      "task rewards [ 0.57619365  0.62803332  0.38313983  0.92888937]\n",
      "[chosen task]  3\n",
      "mu [-0.00292463 -0.01314532 -0.01480554  0.00696741]\n",
      "sigma [ 0.01995956  0.01984019  0.01992547  0.01272011]\n",
      "ucb [-0.00272503 -0.01294692 -0.01460628  0.00709461]\n",
      "performance 0.648067482952 progress 0.0190034406617\n",
      "task rewards [ 0.57619365  0.65724937  0.42667463  0.93215228]\n",
      "[chosen task]  3\n",
      "mu [-0.00217795 -0.00902867 -0.0106262   0.0100871 ]\n",
      "sigma [ 0.01997889  0.01986184  0.01995155  0.01272018]\n",
      "ucb [-0.00197816 -0.00883005 -0.01042669  0.0102143 ]\n",
      "performance 0.654309344609 progress 0.00624186165787\n",
      "task rewards [ 0.57619365  0.68221682  0.42667463  0.93215228]\n",
      "[chosen task]  3\n",
      "mu [-0.00159456 -0.00621934 -0.00753925  0.00947181]\n",
      "sigma [ 0.01998937  0.01987403  0.01996623  0.01271991]\n",
      "ucb [-0.00139466 -0.0060206  -0.00733959  0.00959901]\n",
      "performance 0.609987637428 progress -0.0443217071811\n",
      "task rewards [ 0.57619365  0.55106621  0.3950892   0.91760149]\n",
      "[chosen task]  0\n",
      "mu [-0.00119849 -0.00562639 -0.00581557 -0.00329016]\n",
      "sigma [ 0.01999481  0.0198806   0.01997414  0.01271911]\n",
      "ucb [-0.00099855 -0.00542758 -0.00561583 -0.00316297]\n",
      "performance 0.755728981575 progress 0.145741344147\n",
      "task rewards [ 0.94062977  0.69897512  0.45115875  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.0718754   0.00486173  0.01502407 -0.0043299 ]\n",
      "sigma [ 0.0150988   0.01981966  0.01964025  0.01342893]\n",
      "ucb [ 0.07202639  0.00505993  0.01522048 -0.00419561]\n",
      "performance 0.76198625279 progress 0.00625727121506\n",
      "task rewards [ 0.95194459  0.70009883  0.46374931  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.04762999  0.00286675  0.00978403 -0.00533109]\n",
      "sigma [ 0.01363164  0.0198112   0.01954227  0.01423812]\n",
      "ucb [ 0.0477663   0.00306486  0.00997945 -0.00518871]\n",
      "performance 0.740171282807 progress -0.0218149699834\n",
      "task rewards [ 0.91780434  0.70009883  0.45561975  0.88716221]\n",
      "[chosen task]  0\n",
      "mu [ 0.02539258  0.00081314  0.00473086 -0.00611118]\n",
      "sigma [ 0.01306476  0.01981658  0.01950586  0.0151035 ]\n",
      "ucb [ 0.02552323  0.0010113   0.00492592 -0.00596014]\n",
      "performance 0.755431369458 progress 0.0152600866517\n",
      "task rewards [ 0.95194459  0.70009883  0.43752977  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.01884022  0.00049332  0.00356239 -0.00658481]\n",
      "sigma [ 0.01285831  0.01982718  0.019494    0.01597537]\n",
      "ucb [ 0.0189688   0.00069159  0.00375733 -0.00642506]\n",
      "performance 0.755431369458 progress 0.0\n",
      "task rewards [ 0.95194459  0.70009883  0.43752977  0.93215228]\n",
      "[chosen task]  0\n",
      "mu [ 0.01011076 -0.00024283  0.00164452 -0.00679405]\n",
      "sigma [ 0.01280347  0.01983927  0.01949233  0.01680559]\n",
      "ucb [  1.02387923e-02  -4.44395818e-05   1.83944227e-03  -6.62599499e-03]\n",
      "performance 0.747590771459 progress -0.00784059799939\n",
      "task rewards [ 0.96658666  0.70009883  0.43752977  0.88614782]\n",
      "[chosen task]  0\n",
      "mu [ 0.00159449 -0.00104687 -0.00033774 -0.00674477]\n",
      "sigma [ 0.01279845  0.01985077  0.01949383  0.01755465]\n",
      "ucb [ 0.00172247 -0.00084836 -0.0001428  -0.00656922]\n",
      "performance 0.747590771459 progress 0.0\n",
      "task rewards [ 0.96658666  0.70009883  0.43752977  0.88614782]\n",
      "[chosen task]  2\n",
      "mu [-0.0027027  -0.00138464 -0.00128846 -0.00645089]\n",
      "sigma [ 0.01279686  0.01986063  0.01949526  0.01819632]\n",
      "ucb [-0.00257473 -0.00118603 -0.00109351 -0.00626893]\n",
      "performance 0.632457561722 progress -0.115133209737\n",
      "task rewards [ 0.68217678  0.45812454  0.57175841  0.81777051]\n",
      "[chosen task]  3\n",
      "mu [-0.0106043  -0.05344909 -0.05701907 -0.00837235]\n",
      "sigma [ 0.01349979  0.01583856  0.01499207  0.01871043]\n",
      "ucb [-0.01046931 -0.0532907  -0.05686915 -0.00818525]\n",
      "performance 0.533450538158 progress -0.0990070235641\n",
      "task rewards [ 0.27200994  0.44867267  0.5433487   0.86977084]\n",
      "[chosen task]  0\n",
      "mu [-0.01320276 -0.05656646 -0.05718872 -0.05055391]\n",
      "sigma [ 0.01432034  0.01603822  0.01529261  0.01494517]\n",
      "ucb [-0.01305956 -0.05640608 -0.05703579 -0.05040446]\n",
      "performance 0.706977111452 progress 0.173526573294\n",
      "task rewards [ 0.92318139  0.44757901  0.52736066  0.92978739]\n",
      "[chosen task]  0\n",
      "mu [ 0.04626492 -0.05132559 -0.04387058 -0.04931114]\n",
      "sigma [ 0.01365424  0.01640794  0.01569564  0.01533016]\n",
      "ucb [ 0.04640146 -0.05116151 -0.04371362 -0.04915783]\n",
      "performance 0.702286244174 progress -0.00469086727742\n",
      "task rewards [ 0.86829782  0.44757901  0.5551834   0.93808475]\n",
      "[chosen task]  0\n",
      "mu [ 0.03383641 -0.04824509 -0.04245915 -0.04708989]\n",
      "sigma [ 0.01322728  0.01686585  0.01619759  0.01580943]\n",
      "ucb [ 0.03396868 -0.04807643 -0.04229717 -0.04693179]\n",
      "performance 0.670193484299 progress -0.0320927598752\n",
      "task rewards [ 0.94425914  0.25013604  0.54843944  0.93793932]\n",
      "[chosen task]  0\n",
      "mu [ 0.01699918 -0.04518634 -0.04172553 -0.04402447]\n",
      "sigma [ 0.01296355  0.01736685  0.01674791  0.01636208]\n",
      "ucb [ 0.01712882 -0.04501267 -0.04155805 -0.04386084]\n",
      "performance 0.667606674336 progress -0.00258680996337\n",
      "task rewards [ 0.94425914  0.25013604  0.54624413  0.92978739]\n",
      "[chosen task]  0\n",
      "mu [ 0.0110857  -0.04095985 -0.03836678 -0.04027636]\n",
      "sigma [ 0.01281544  0.01786764  0.01729816  0.01695337]\n",
      "ucb [ 0.01121385 -0.04078117 -0.0381938  -0.04010682]\n",
      "performance 0.668910595544 progress 0.00130392120828\n",
      "task rewards [ 0.94465515  0.24975687  0.54420951  0.93702084]\n",
      "[chosen task]  0\n",
      "mu [ 0.00714216 -0.03634046 -0.03436907 -0.03608228]\n",
      "sigma [ 0.01274579  0.01833264  0.01780858  0.01754324]\n",
      "ucb [ 0.00726962 -0.03615714 -0.03419098 -0.03590684]\n",
      "performance 0.653754922725 progress -0.0151556728189\n",
      "task rewards [ 0.92551941  0.25601967  0.49539586  0.93808475]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e012210>]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhmEYhmEYhmEYhmEYhmHkO/8PYDVTn5KAF4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f0fbcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "performances = []\n",
    "for it in range(300):\n",
    "    learner.run(num_epochs=1, num_episodes=10)\n",
    "    print '[chosen task] ', learner.last_task_ti\n",
    "    print 'mu', learner.mu\n",
    "    print 'sigma', learner.sigma\n",
    "    print 'ucb', learner.ucb\n",
    "    print 'performance', learner.last_performance, 'progress', learner.last_progress\n",
    "    print 'task rewards', learner.last_task_performance\n",
    "    performances.append(learner.last_performance)\n",
    "plot(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 0 train_performances 0.0920402622854\n",
      "it 1 train_performances 0.118992880796\n",
      "it 2 train_performances 0.111199549655\n",
      "it 3 train_performances 0.158559723869\n",
      "it 4 train_performances 0.143333253018\n",
      "it 5 train_performances 0.175929883115\n",
      "it 6 train_performances 0.212811111651\n",
      "it 7 train_performances 0.203952869289\n",
      "it 8 train_performances 0.203841818267\n",
      "it 9 train_performances 0.168441968753\n",
      "it 10 train_performances 0.205722833504\n",
      "it 11 train_performances 0.213745465055\n",
      "it 12 train_performances 0.209761377041\n",
      "it 13 train_performances 0.198638274656\n",
      "it 14 train_performances 0.190825329038\n",
      "it 15 train_performances 0.225280792989\n",
      "it 16 train_performances 0.226469680511\n",
      "it 17 train_performances 0.241584462069\n",
      "it 18 train_performances 0.23093182572\n",
      "it 19 train_performances 0.247481650669\n",
      "it 20 train_performances 0.257738181684\n",
      "it 21 train_performances 0.26055848244\n",
      "it 22 train_performances 0.273504328721\n",
      "it 23 train_performances 0.260772491393\n",
      "it 24 train_performances 0.259608361495\n",
      "it 25 train_performances 0.258191454666\n",
      "it 26 train_performances 0.269491485721\n",
      "it 27 train_performances 0.26591401538\n",
      "it 28 train_performances 0.283867426052\n",
      "it 29 train_performances 0.287510934891\n",
      "it 30 train_performances 0.287505424867\n",
      "it 31 train_performances 0.287505424867\n",
      "it 32 train_performances 0.279547494372\n",
      "it 33 train_performances 0.278590855927\n",
      "it 34 train_performances 0.279682313642\n",
      "it 35 train_performances 0.288813150153\n",
      "it 36 train_performances 0.288265064426\n",
      "it 37 train_performances 0.279231022479\n",
      "it 38 train_performances 0.263580241548\n",
      "it 39 train_performances 0.297161854667\n",
      "it 40 train_performances 0.285287350601\n",
      "it 41 train_performances 0.289429880658\n",
      "it 42 train_performances 0.289382414681\n",
      "it 43 train_performances 0.297306506048\n",
      "it 44 train_performances 0.289295332561\n",
      "it 45 train_performances 0.256345751674\n",
      "it 46 train_performances 0.288547918635\n",
      "it 47 train_performances 0.288547918635\n",
      "it 48 train_performances 0.287865501966\n",
      "it 49 train_performances 0.283883068401\n",
      "it 50 train_performances 0.283835602423\n",
      "it 51 train_performances 0.286511125063\n",
      "it 52 train_performances 0.297570058909\n",
      "it 53 train_performances 0.282350611791\n",
      "it 54 train_performances 0.295535245423\n",
      "it 55 train_performances 0.281364346231\n",
      "it 56 train_performances 0.291783918275\n",
      "it 57 train_performances 0.295384608443\n",
      "it 58 train_performances 0.302296540842\n",
      "it 59 train_performances 0.305650768194\n",
      "it 60 train_performances 0.289119590856\n",
      "it 61 train_performances 0.286064545637\n",
      "it 62 train_performances 0.285456642759\n",
      "it 63 train_performances 0.286496580039\n",
      "it 64 train_performances 0.285543269377\n",
      "it 65 train_performances 0.284379543123\n",
      "it 66 train_performances 0.284801806957\n",
      "it 67 train_performances 0.282640855688\n",
      "it 68 train_performances 0.286893054708\n",
      "it 69 train_performances 0.286893054708\n",
      "it 70 train_performances 0.287225449957\n",
      "it 71 train_performances 0.287429932445\n",
      "it 72 train_performances 0.2872858895\n",
      "it 73 train_performances 0.284087424263\n",
      "it 74 train_performances 0.282468593998\n",
      "it 75 train_performances 0.283894771358\n",
      "it 76 train_performances 0.283895808615\n",
      "it 77 train_performances 0.279217961554\n",
      "it 78 train_performances 0.283365241447\n",
      "it 79 train_performances 0.278972829927\n",
      "it 80 train_performances 0.280519087766\n",
      "it 81 train_performances 0.273865931294\n",
      "it 82 train_performances 0.28317111761\n",
      "it 83 train_performances 0.282719043238\n",
      "it 84 train_performances 0.282637559849\n",
      "it 85 train_performances 0.283734415844\n",
      "it 86 train_performances 0.284018627793\n",
      "it 87 train_performances 0.284018627793\n",
      "it 88 train_performances 0.286490553223\n",
      "it 89 train_performances 0.286499758363\n",
      "it 90 train_performances 0.286493396298\n",
      "it 91 train_performances 0.283973571033\n",
      "it 92 train_performances 0.284071152921\n",
      "it 93 train_performances 0.280969720572\n",
      "it 94 train_performances 0.291975159132\n",
      "it 95 train_performances 0.30052350253\n",
      "it 96 train_performances 0.291932668475\n",
      "it 97 train_performances 0.294873570836\n",
      "it 98 train_performances 0.294614898063\n",
      "it 99 train_performances 0.300266317028\n",
      "it 100 train_performances 0.3002856536\n",
      "it 101 train_performances 0.300186619403\n",
      "it 102 train_performances 0.300149996968\n",
      "it 103 train_performances 0.300614083583\n",
      "it 104 train_performances 0.300029694375\n",
      "it 105 train_performances 0.300906594433\n",
      "it 106 train_performances 0.300076479002\n",
      "it 107 train_performances 0.299898067414\n",
      "it 108 train_performances 0.304693314874\n",
      "it 109 train_performances 0.321086164446\n",
      "it 110 train_performances 0.29765407844\n",
      "it 111 train_performances 0.287753944293\n",
      "it 112 train_performances 0.271736600565\n",
      "it 113 train_performances 0.257489376562\n",
      "it 114 train_performances 0.277589808443\n",
      "it 115 train_performances 0.271514012299\n",
      "it 116 train_performances 0.308076116682\n",
      "it 117 train_performances 0.312007412506\n",
      "it 118 train_performances 0.29051398985\n",
      "it 119 train_performances 0.290503597641\n",
      "it 120 train_performances 0.277764457122\n",
      "it 121 train_performances 0.276924758054\n",
      "it 122 train_performances 0.277874690092\n",
      "it 123 train_performances 0.285501775805\n",
      "it 124 train_performances 0.282950824003\n",
      "it 125 train_performances 0.282757123503\n",
      "it 126 train_performances 0.284551324553\n",
      "it 127 train_performances 0.283058062135\n",
      "it 128 train_performances 0.284536687435\n",
      "it 129 train_performances 0.286612781462\n",
      "it 130 train_performances 0.28660589687\n",
      "it 131 train_performances 0.281481507924\n",
      "it 132 train_performances 0.281105350806\n",
      "it 133 train_performances 0.286304978623\n",
      "it 134 train_performances 0.297534031534\n",
      "it 135 train_performances 0.292134144035\n",
      "it 136 train_performances 0.294701287093\n",
      "it 137 train_performances 0.293983085004\n",
      "it 138 train_performances 0.291866682779\n",
      "it 139 train_performances 0.291328060956\n",
      "it 140 train_performances 0.274453135414\n",
      "it 141 train_performances 0.290006321844\n",
      "it 142 train_performances 0.290684091227\n",
      "it 143 train_performances 0.290666137664\n",
      "it 144 train_performances 0.274743833795\n",
      "it 145 train_performances 0.293749544962\n",
      "it 146 train_performances 0.293632426824\n",
      "it 147 train_performances 0.294692990664\n",
      "it 148 train_performances 0.293632426824\n",
      "it 149 train_performances 0.292165206828\n",
      "it 150 train_performances 0.274819507074\n",
      "it 151 train_performances 0.278081254443\n",
      "it 152 train_performances 0.279724072459\n",
      "it 153 train_performances 0.279726242003\n",
      "it 154 train_performances 0.279630615516\n",
      "it 155 train_performances 0.276304692077\n",
      "it 156 train_performances 0.275599544053\n",
      "it 157 train_performances 0.278468969342\n",
      "it 158 train_performances 0.26070851331\n",
      "it 159 train_performances 0.253113855965\n",
      "it 160 train_performances 0.289839664157\n",
      "it 161 train_performances 0.28909647475\n",
      "it 162 train_performances 0.292620996706\n",
      "it 163 train_performances 0.299406841694\n",
      "it 164 train_performances 0.30924164519\n",
      "it 165 train_performances 0.31794993508\n",
      "it 166 train_performances 0.302093163069\n",
      "it 167 train_performances 0.295882917804\n",
      "it 168 train_performances 0.302862490399\n",
      "it 169 train_performances 0.299353060662\n",
      "it 170 train_performances 0.304539934105\n",
      "it 171 train_performances 0.312401597866\n",
      "it 172 train_performances 0.305038314753\n",
      "it 173 train_performances 0.305914798649\n",
      "it 174 train_performances 0.300156031939\n",
      "it 175 train_performances 0.319180243609\n",
      "it 176 train_performances 0.319180243609\n",
      "it 177 train_performances 0.308574777088\n",
      "it 178 train_performances 0.30861817152\n",
      "it 179 train_performances 0.30861817152\n",
      "it 180 train_performances 0.315379166781\n",
      "it 181 train_performances 0.313440152659\n",
      "it 182 train_performances 0.310657044174\n",
      "it 183 train_performances 0.310088718487\n",
      "it 184 train_performances 0.309823701875\n",
      "it 185 train_performances 0.307983401497\n",
      "it 186 train_performances 0.308025748798\n",
      "it 187 train_performances 0.308920892507\n",
      "it 188 train_performances 0.31014725822\n",
      "it 189 train_performances 0.296811723325\n",
      "it 190 train_performances 0.298636894872\n",
      "it 191 train_performances 0.286548486985\n",
      "it 192 train_performances 0.286800932081\n",
      "it 193 train_performances 0.286972114906\n",
      "it 194 train_performances 0.287598036677\n",
      "it 195 train_performances 0.293980774219\n",
      "it 196 train_performances 0.296524441577\n",
      "it 197 train_performances 0.279538117516\n",
      "it 198 train_performances 0.279914134917\n",
      "it 199 train_performances 0.283955285137\n",
      "it 200 train_performances 0.282736688495\n",
      "it 201 train_performances 0.277004292969\n",
      "it 202 train_performances 0.279646914877\n",
      "it 203 train_performances 0.274173097133\n",
      "it 204 train_performances 0.288505362284\n",
      "it 205 train_performances 0.288343545661\n",
      "it 206 train_performances 0.286776146932\n",
      "it 207 train_performances 0.273188372612\n",
      "it 208 train_performances 0.271944494373\n",
      "it 209 train_performances 0.280224521891\n",
      "it 210 train_performances 0.281860617876\n",
      "it 211 train_performances 0.279662938547\n",
      "it 212 train_performances 0.282255326198\n",
      "it 213 train_performances 0.289822521385\n",
      "it 214 train_performances 0.289204772774\n",
      "it 215 train_performances 0.29012226925\n",
      "it 216 train_performances 0.289625379091\n",
      "it 217 train_performances 0.297373284144\n",
      "it 218 train_performances 0.288470092417\n",
      "it 219 train_performances 0.284398792123\n",
      "it 220 train_performances 0.28587398682\n",
      "it 221 train_performances 0.285925553533\n",
      "it 222 train_performances 0.28629851799\n",
      "it 223 train_performances 0.288520586774\n",
      "it 224 train_performances 0.288535921048\n",
      "it 225 train_performances 0.285940549946\n",
      "it 226 train_performances 0.286760040615\n",
      "it 227 train_performances 0.285991919544\n",
      "it 228 train_performances 0.29671906941\n",
      "it 229 train_performances 0.296185800138\n",
      "it 230 train_performances 0.296185800138\n",
      "it 231 train_performances 0.295283842281\n",
      "it 232 train_performances 0.29642988404\n",
      "it 233 train_performances 0.285421946226\n",
      "it 234 train_performances 0.271099401036\n",
      "it 235 train_performances 0.272471582013\n",
      "it 236 train_performances 0.28793151813\n",
      "it 237 train_performances 0.288531674084\n",
      "it 238 train_performances 0.286781786103\n",
      "it 239 train_performances 0.288478368036\n",
      "it 240 train_performances 0.286519343794\n",
      "it 241 train_performances 0.289374587812\n",
      "it 242 train_performances 0.289239811356\n",
      "it 243 train_performances 0.296602914388\n",
      "it 244 train_performances 0.296602914388\n",
      "it 245 train_performances 0.299377806709\n",
      "it 246 train_performances 0.298158641006\n",
      "it 247 train_performances 0.29691586488\n",
      "it 248 train_performances 0.307215587917\n",
      "it 249 train_performances 0.295184964503\n",
      "it 250 train_performances 0.295582952072\n",
      "it 251 train_performances 0.300196167516\n",
      "it 252 train_performances 0.301415522846\n",
      "it 253 train_performances 0.302120448313\n",
      "it 254 train_performances 0.301213052663\n",
      "it 255 train_performances 0.302108869879\n",
      "it 256 train_performances 0.301356446558\n",
      "it 257 train_performances 0.300149423103\n",
      "it 258 train_performances 0.300196138239\n",
      "it 259 train_performances 0.300207716672\n",
      "it 260 train_performances 0.300201943846\n",
      "it 261 train_performances 0.299949077398\n",
      "it 262 train_performances 0.299949077398\n",
      "it 263 train_performances 0.291136487174\n",
      "it 264 train_performances 0.285208555107\n",
      "it 265 train_performances 0.275920737755\n",
      "it 266 train_performances 0.275829560014\n",
      "it 267 train_performances 0.289765692551\n",
      "it 268 train_performances 0.287165595851\n",
      "it 269 train_performances 0.277974229932\n",
      "it 270 train_performances 0.278991886932\n",
      "it 271 train_performances 0.302899436642\n",
      "it 272 train_performances 0.302066853637\n",
      "it 273 train_performances 0.299413649027\n",
      "it 274 train_performances 0.291986350669\n",
      "it 275 train_performances 0.28294865732\n",
      "it 276 train_performances 0.28326846554\n",
      "it 277 train_performances 0.284036303624\n",
      "it 278 train_performances 0.282843565139\n",
      "it 279 train_performances 0.294632930359\n",
      "it 280 train_performances 0.291078059004\n",
      "it 281 train_performances 0.304836872372\n",
      "it 282 train_performances 0.302910289529\n",
      "it 283 train_performances 0.298757848076\n",
      "it 284 train_performances 0.29080832075\n",
      "it 285 train_performances 0.305837512353\n",
      "it 286 train_performances 0.305223691288\n",
      "it 287 train_performances 0.304327385149\n",
      "it 288 train_performances 0.301086920004\n",
      "it 289 train_performances 0.302692745843\n",
      "it 290 train_performances 0.302399972795\n",
      "it 291 train_performances 0.299827956548\n",
      "it 292 train_performances 0.299952258119\n",
      "it 293 train_performances 0.308808365026\n",
      "it 294 train_performances 0.311307697716\n",
      "it 295 train_performances 0.320518371848\n",
      "it 296 train_performances 0.319273361583\n",
      "it 297 train_performances 0.321308012866\n",
      "it 298 train_performances 0.321275925682\n",
      "it 299 train_performances 0.321275925682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e07e210>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEACAYAAABbMHZzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiIiIiIiIiIiIiIiIiIiIiIiMj/B2QwwWhBPdL+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cb87990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dqn = DQN(tasks[0], lambda states: arch.two_layer(states, H * W * 2, 32, 4))\n",
    "dqn = DQN(tasks[0], two_stream_arch)\n",
    "learner = SingleLearnerSequential(dqn, tasks, \n",
    "                           lr=1e-4, memory_size=250)\n",
    "train_performances = []\n",
    "for it in range(300):\n",
    "    learner.run(num_epochs = 1, num_episodes = 10)\n",
    "    train_performances.append(eval_dataset(dqn, tasks))\n",
    "    print 'it', it, 'train_performances', train_performances[-1]\n",
    "plot(train_performances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19458254,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  1.14922715,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  1.26598974,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.12498521]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(learner.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tasks2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-4ed8894d051c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'it'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_err'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tasks2' is not defined"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "for it in range(300):\n",
    "    learner.run(num_epochs = 1, num_episodes = 10)\n",
    "    train_errors.append(eval_dataset(dqn, tasks2))\n",
    "    print 'it', it, 'train_err', train_errors[-1]\n",
    "figure(1)\n",
    "plot(train_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
