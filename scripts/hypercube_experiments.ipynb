{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scriptinit\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import util\n",
    "from hypercube import *\n",
    "from experiment import *\n",
    "from diagnostics import VisualizeTrajectoryController\n",
    "from agent import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "# When running final experiments, also set the numpy seed so the run is reproducible.\n",
    "SEED=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step up argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "def tup(s):\n",
    "    try:\n",
    "        s = s[1:-1]  # strip off the ( ) \n",
    "        return tuple(map(int, s.split(',')))\n",
    "    except:\n",
    "        raise argparse.ArgumentTypeError(\"Must give a tuple!\")\n",
    "\n",
    "# task arguments\n",
    "parser.add_argument('-d', '--dimensions', type=tup, required=True)  # expects a (x, y, z, ...) tuple\n",
    "parser.add_argument('-as', '--action_stochasticity', type=float, required=True)\n",
    "parser.add_argument('-wp', '--wall_penalty', type=float, required=True)\n",
    "parser.add_argument('-tp', '--time_penalty', type=float, required=True)\n",
    "parser.add_argument('-r', '--reward', type=float, required=True)\n",
    "parser.add_argument('-g', '--gamma', type=float, required=True)\n",
    "parser.add_argument('-ms', '--maximum_steps', type=int)\n",
    "\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('-hd', '--hidden_dimension', type=int, required=True)\n",
    "parser.add_argument('-lr', '--lr', type=float, required=True)\n",
    "parser.add_argument('-eps', '--epsilon', type=float, required=True)\n",
    "\n",
    "# curriculum argument\n",
    "parser.add_argument('-up', '--update_every', type=float, required=True)\n",
    "\n",
    "\n",
    "# experiment arguments\n",
    "parser.add_argument('-me', '--max_episodes', type=int, required=True)\n",
    "parser.add_argument('-rw', '--report_wait', type=int, required=True)\n",
    "parser.add_argument('-sw', '--save_wait', type=int, required=True)\n",
    "parser.add_argument('-vw', '--visualize_wait', type=int)\n",
    "parser.add_argument('-fo', '--fully_observed', type=int, required=True) \n",
    "parser.add_argument('-ss', '--state_samples', type=int, required=True)\n",
    "parser.add_argument('-es', '--eval_samples', type=int, required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if util.in_ipython():\n",
    "    args = parser.parse_args(['-d','(5, 5)', '-as', '0.', '-wp', '-0.1', '-tp', '-0.1', '-r', '4', '-g', '0.9',\n",
    "                              '-hd', '128', '-lr', '0.05', '-eps', '0.15', '-me', '1000', '-rw', '2',\n",
    "                              '-sw', '5', '-fo', '1', '-ss', '25', '-es', '5', '-ms', '500', '-up', '1'])\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "hyperparams = vars(args)\n",
    "\n",
    "# load into namespace and log to metadata\n",
    "for var, val in hyperparams.iteritems():\n",
    "    exec(\"{0} = hyperparams['{0}']\".format(var))\n",
    "    util.metadata(var, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the dataset\n",
    "goal_length = 2 ** len(dimensions)\n",
    "goals = [\"\".join(seq) for seq in itertools.product(\"01\", repeat=goal_length)]  # all bit strings of length # corners in world\n",
    "\n",
    "# remove the all zeros strings and convert to numpy 1D arrays\n",
    "goals = [np.asarray(list(g)).astype(int) for g in goals if int(g) > 0]\n",
    "\n",
    "# randomly shuffle the data (ensure the same train/test split between runs...)\n",
    "random.seed(SEED)\n",
    "random.shuffle(goals)\n",
    "\n",
    "# get goal training/test splits\n",
    "split = int(0.8 * len(goals))\n",
    "train, test = goals[:split], goals[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize the hypercube maze and the task\n",
    "world = np.zeros(dimensions)  # no walls for now...\n",
    "maze = HyperCubeMaze(dimensions=dimensions, action_stoch=action_stochasticity, grid=world)\n",
    "\n",
    "task = HyperCubeMazeTask(hypercubemaze=maze, initial_goal=train[0],\n",
    "                         wall_penalty=wall_penalty, time_penalty=time_penalty,\n",
    "                         reward=reward, gamma=gamma, fully_observed=fully_observed,\n",
    "                         maximum_steps=maximum_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile the agent\n",
    "agent = DQN(task, hidden_dim=hidden_dimension, lr=lr, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the experiment environment\n",
    "controllers = [BasicController(report_wait=report_wait, save_wait=save_wait, max_episodes=max_episodes)]\n",
    "\n",
    "# fixed curriculum for now (uniformly sample a goal on each episode)... this is something to experiment with!\n",
    "controllers.append(HyperCubeCurriculum(goals=train, update_every=update_every, curr_type='uniform'))\n",
    "\n",
    "if len(dimensions) == 2 and visualize_wait is not None and visualize_wait > 0:\n",
    "    controllers.append(VisualizeTrajectoryController(visualize_wait=visualize_wait, dir_name='trajectories'))\n",
    "\n",
    "observers = [AverageRewardObserver(report_wait=report_wait), AverageQValueObserver(state_samples=state_samples, report_wait=report_wait)]\n",
    "\n",
    "\n",
    "goal_dsets = {'train' : train, 'test': test}\n",
    "observers.append(HyperCubeObserver(goal_dsets=goal_dsets, eval_samples=eval_samples, report_wait=report_wait))\n",
    "\n",
    "experiment = Experiment(agent, task, controllers=controllers, observers=observers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# launch experiment\n",
    "experiment.run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
